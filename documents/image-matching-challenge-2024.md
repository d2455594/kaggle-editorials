---
tags:
  - Kaggle
  - 画像マッチング
  - 画像認識処理
startdate: 2024-03-26
enddate: 2024-06-04
---
# Image Matching Challenge 2024 - Hexathlon
https://www.kaggle.com/competitions/image-matching-challenge-2024

**概要 (Overview)**

* **目的:** このコンペティションの目的は、同じシーンやオブジェクトを異なる視点から撮影した画像のペア（またはセット）間で、正確な対応点を見つけ出し、それらの画像間の相対的なカメラポーズ（回転と並進、すなわち3次元的な位置関係）を高精度に推定するアルゴリズムを開発することです。
* **背景:** 画像マッチングとポーズ推定は、3Dリコンストラクション（Structure from Motion - SfM）、拡張現実（AR）、ロボティクス、画像スティッチングなど、コンピュータビジョンの多くの応用分野における基本的な技術です。"Hexathlon"（六種競技）という名前が示すように、このチャレンジはおそらく、視点の変化が大きい、照明条件が異なる、繰り返しパターンが多いなど、様々な困難な条件下での画像マッチング能力を、複数の異なるデータセットやタスクを通じて総合的に評価することを目指しています。
* **課題:** 特に困難な条件下（大きな視点変化、照明変化、テクスチャの欠如や繰り返しなど）で、画像間の正確な対応点を見つけ、精密な幾何学的関係（カメラポーズ）を推定することは非常に難しい課題です。参加者は、多様なシナリオに対して頑健（ロバスト）なマッチングおよびポーズ推定手法を開発することが求められます。

**データセットの形式 (Dataset Format)**

提供される主なデータは以下の通りです。

1.  **テスト画像セット:**
    * これが参加者が主に取り組むデータです。様々なシーン（例: ランドマーク、一般的な物体など）を撮影した画像のセット（多くはペア）が含まれます。
    * "Hexathlon" の名の通り、異なる特性を持つ複数のデータセット（例: `dataset1`, `dataset2`, ... `dataset6`）で構成される可能性があります。各データセット内は、シーンごとに画像ファイル（JPEGまたはPNG形式が一般的）がグループ化されています。
    * `test.csv`のようなファイルで、処理対象となる画像ペア（またはセット）のリストが指定されます。

2.  **トレーニングデータ:**
    * 従来の機械学習コンペのように大規模なラベル付き訓練データセットが提供されるとは限りません。参加者は、公開されている他のデータセットを用いたり、自己教師あり学習などの手法を用いたりして、自身の画像マッチングアルゴリズム（特徴点抽出、記述、マッチングなど）を訓練・開発することが期待される場合があります。
    * ただし、ローカルでの開発や検証のために、いくつかのサンプル画像ペアと、それに対応する正解のカメラポーズや疎な対応点が提供される可能性はあります。

3.  **メタデータ:**
    * 必要に応じて、カメラの内部パラメータ（焦点距離、主点など）が提供される場合があります。これは、基礎行列（Fundamental Matrix）ではなく、基本行列（Essential Matrix）を推定したり、ポーズをより正確に復元したりする際に役立ちます。

4.  **`sample_submission.csv`**:
    * 提出が必要なフォーマットを示すサンプルファイル。通常、画像ペアを識別するIDと、推定された**基礎行列（Fundamental Matrix）**の要素（3x3行列の9つの数値）を特定の形式で記述する列が含まれます。

**評価指標 (Evaluation Metric)**

* **指標:** **Mean Average Accuracy (mAA)** - 平均平均精度
* **計算方法:** この指標は、提出された基礎行列（Fundamental Matrix）から復元された**相対カメラポーズ（Relative Camera Pose）の精度**に基づいて計算されます。
    1.  参加者が提出した基礎行列から、各画像ペア間の相対的な回転（Rotation, R）と並進（Translation, t）を推定します。
    2.  推定されたポーズ (R, t) を、隠されている真のポーズと比較し、回転と並進の角度誤差を計算します。
    3.  複数の誤差閾値（例: 回転誤差1°, 2°, ..., 10°）に対して、推定ポーズがその閾値内に収まっているかどうかを判定し、精度（Accuracy）を計算します。
    4.  各シーン（画像ペア）について、これらの精度を異なる閾値でプロットした際の曲線下面積（Area Under the Curve）、すなわち**平均精度（Average Accuracy - AA）**を計算します。
    5.  最後に、全てのテストシーン/データセットにわたるAAスコアを平均して、最終的な **mAA (Mean Average Accuracy)** スコアを算出します。
* **意味:** mAAは、様々な誤差許容度において、モデルがどれだけ正確に画像間の幾何学的関係（ポーズ）を推定できたかを総合的に評価する指標です。値が大きいほど、より多くの画像ペアに対して、より高い精度でポーズ推定が成功していることを示します。

要約すると、Image Matching Challenge 2024は、様々な条件下での画像ペアから相対カメラポーズを正確に推定するタスクです。データは主にテスト用の画像セットで構成され、参加者は各ペアの基礎行列（Fundamental Matrix）を提出します。性能は、推定されたポーズの精度を複数の誤差閾値で評価し、全データセットで平均したmAA（Mean Average Accuracy）によって測られます。

---

**全体的な傾向:**

このコンペでは、様々な条件下で撮影された画像群から詳細な3Dマップを生成することが課題です。上位解法では、疎な特徴点検出器（ALIKED, SuperPoint, DISK, DeDoDe, SIFTなど）とそれに対応する特徴点マッチング器（LightGlue, SuperGlue, AdaLAM, Nearest Neighbor, Dual Softmaxなど）を組み合わせたパイプラインが主流です。3D復元にはCOLMAPが広く利用されています。透明なオブジェクトを含むシーンに対する特別な処理や、画像回転への対応、異なるスケールやクロップからの特徴点抽出、アンサンブル学習などが重要なテクニックとして用いられています。

**各解法の詳細:**

**1位 (Approvers)**

- **アプローチ:** 非透明シーンにはCOLMAPを用いた3D画像再構成（I3DR）、透明シーンには簡略化された直接画像姿勢推定（DIP）。疎な特徴点検出器とマッチング器のアンサンブル。
- **アーキテクチャ:** ALIKED特徴点検出器、LightGlue特徴点マッチング器、COLMAP（I3DR）、カスタムDIPモジュール。
- **アルゴリズム:** RANSAC（2視点間の幾何学）、DBSCAN（密な点群クラスタリング）、TSP（透明シーンの画像順序推定）。
- **テクニック:**
    - **I3DRモジュール:** マッチ数に基づいた段階的な画像ペアのフィルタリング、ALIKED+LightGlueのファインチューニング設定、キーポイントと記述子のキャッシュ、マルチGPUアクセラレーション、異なるスケールとクロップからのマッチのテスト時拡張（TTA）、画像ごとの新しいクロップ方法、画像ペアの一方の回転によるマッチ数最大化、シーン再構成の繰り返し、複数再構成のマージ（Hornアラインメント）、OmniGlueとのマージ（プライベート提出）。
    - **DIPモジュール:** 透明シーン向けに、オブジェクトの回転順に画像を並べ、回転行列と並進ベクトルを計算。カメラをオブジェクトを中心とした円上に配置する仮定。
    - **CV:** 透明シーンと非透明シーンで別々に検証。COLMAPは1スレッドに制限。

**2位**

- **アプローチ:** 非透明シーンにはMST（最小全域木）支援の粗密SfMソリューション、透明・反射シーンには画像撮影順序の推定とカメラ姿勢の配置。
- **アーキテクチャ:** ALIKED, DISK, SIFT (局所特徴量)、DINO (パッチ特徴量)、VLAD (グローバル記述子)。COLMAP。
- **アルゴリズム:** MST（データ関連付け）、VLAD（グローバル記述子）、TSP（透明シーンの画像順序推定）、pixsfm（SfMモデルの最適化）、HLoc（未登録画像の再配置）。
- **テクニック:**
    - **前処理:** 画像の回転検出と補正、シーンの透明性の検出、カメラ内部パラメータの共有（条件付き）。
    - **グローバル特徴量:** 点特徴量（ALIKED）とパッチ特徴量（DINO）を組み合わせたカスタム記述子。空間的関係に基づいて対応付け、クラスタリングとVLADで生成。
    - **局所特徴量:** Dedode v2 + Dual Softmax、DISK + LightGlue、SIFT + Nearest Neighborのアンサンブル。
    - **MST支援SfM:** MSTを用いてグローバルに最適なデータ関連付けを行い粗いモデルを構築し、その後、完全なデータ関連付けと粗いモデルを初期値として幾何学的検証を行い、最終モデルを生成。
    - **透明シーン:** グローバル特徴量に基づく類似度グラフから最小コストパスを計算して画像撮影順序を決定。カメラを閉ループに配置して姿勢を計算。シリンダーのグローバル特徴量の2D平面レイアウトも利用。
    - **後処理:** pixsfmによるSfMモデルの最適化、HLocによる未登録画像の再配置。

**3位 (VGGSfM)**

- **アプローチ:** VGGSfM（Visual Geometry Grounded Deep Structure From Motion）を核としたソリューション。すべてのフレームにVGGSfMを適用、またはpycolmapパイプラインに統合。
- **アーキテクチャ:** VGGSfM（カメラ予測器、トラック予測器）、pycolmap。特徴点検出器（Superpoint）、グローバル記述子（NetVLAD, DINO V2）。
- **アルゴリズム:** VGGSfMのカメラ予測、トラック予測、三角測量、バンドル調整。pycolmapの増分マッピング。Umeyamaアルゴリズム（座標系アラインメント）。DBSCAN（透明オブジェクトの領域抽出）。TSP（透明シーンの画像順序推定 - 未採用）。RAFT（オプティカルフロー - 未採用）。
- **テクニック:**
    - **VGGSfMの全フレーム適用:** 評価セットで有効。
    - **追加トラック:** VGGSfMトラック予測器で推定したトラックをpycolmapに追加。近傍フレーム（NetVLAD/DINO V2で選択）でSuperpointを用いてクエリ点を検出し、対応するトラックを検出。
    - **SfMトラックの改良:** pycolmapで再構成されたSfMトラックをVGGSfMの精密トラック予測器で改良し、pycolmapの再構成を更新。バンドル調整を再実行。
    - **欠落画像の再配置:** VGGSfMを使用して欠落画像のカメラ姿勢を予測し、Umeyamaアルゴリズムでpycolmapの座標系にアラインメント。
    - **その他:** 画像回転の処理（check_orientation）、ALIKED+LightGlueとSP+LightGlueの両方のマッチを使用、透明画像の関心領域抽出（DBSCAN）。

**4位**

- **アプローチ:** 透明シーンと非透明シーンを別々に処理。ALIKED+LightGlueを基本とし、画像回転への対応、透明オブジェクトのフォアグラウンドセグメンテーション、網羅的なペアマッチング、全画像の利用。
- **アーキテクチャ:** ALIKED (特徴点検出器)、LightGlue (特徴点マッチング器)、DINOv2 Segmenter (フォアグラウンドセグメンテーション)、COLMAP。
- **アルゴリズム:** DINOv2 Segmenter（セマンティックセグメンテーション）。
- **テクニック:**
    - **非透明シーン:** 画像を90度ずつ回転させながらALIKEDでキーポイントを検出しキャッシュ。LightGlueでマッチング評価（異なる回転パターンと閾値を試行）。
    - **透明シーン:** DINOv2 Segmenterで「bottle」クラスをフォアグラウンドとしてセグメンテーション。オリジナルスケールでALIKEDを用いてフォアグラウンド領域のみでキーポイントを検出。対応するグリッド間で特徴点をマッチング。
    - **その他:** シーン内のすべてのペアに対して網羅的なマッチングを実行。`submission.csv` にない画像も利用。並列処理（CPU/GPU）、ユーティリティスクリプトによるオフラインパッケージインストール。

**5位**

- **アプローチ:** グローバル記述子によるペア候補の提案、候補リスト内のペアのマッチング、Colmapによる再構成。カテゴリごとにパイプラインをカスタマイズ。透明オブジェクトに対する特別な処理。
- **アーキテクチャ:** EVA-CLIP Base, ConvNeXt Base, Dinov2 ViT Base (グローバル記述子抽出)、SuperPoint, ALIKED, DISK (特徴点検出器)、SuperGlue, GlueStick, LightGlue, OmniGlue, SIFT + NN (特徴点マッチング器)、COLMAP。MobileSAM (オブジェクト検出)。RAFT (オプティカルフロー - 未採用)。
- **アルゴリズム:** MobileSAM（オブジェクトのマスク検出）、DBSCAN（オブジェクト検出 - 未採用）、RAFT（オプティカルフロー - 未採用）、TSP（透明オブジェクトの画像順序推定 - 未採用）。
- **テクニック:**
    - **ペア候補の発見:** `timm` のpretrainedモデルからグローバル特徴量を抽出し、コサイン類似度に基づいてペアを提案（シーンタイプごとに閾値を調整）。
    - **画像マッチング:** 検出器ベースの手法（SuperPoint, ALIKED, DISK）とLightGlueを主に使用。SIFT + NNも試行。
    - **再構成:** COLMAPのパラメータ調整（シングルカメラ、手動初期ペア、複数回の増分マッピングを試行）。
    - **透明オブジェクト:** MobileSAMでオブジェクトのマスクを検出し、キーポイント抽出器でオブジェクトのキーポイントを抽出。キーポイントを最も多く含む最小のマスクを見つけ、そのマスクを含む最小のバウンディングボックスを取得。連続するペアのマッチングに焦点を当てる（リングマッチ）。オプティカルフローとグローバル埋め込みの組み合わせ、またはマッチ数に基づくペアスコアリングと上位2ペアの選択による画像順序推定。
    - **その他:** 画像回転のチェック（check_orientation）。

**6位**

- **アプローチ:** 一般シーンにはDetector-free SfM（DFSfM）、透明シーンには画像順序復元戦略。
- **アーキテクチャ:** DFSfM（LoFTR, DKM, RoMaなどの密な特徴点マッチング器、アテンションベースのマルチビューマッチングモジュール）、NetVLAD（画像検索）、tokencut（透明オブジェクトのセグメンテーション）、COLMAP。
- **アルゴリズム:** DFSfMの粗密SfM、信頼度ガイド付きマージ、反復改良パイプライン。NetVLADによる画像検索、tokencutによる前景セグメンテーション、TSP（透明シーンの画像順序推定）。RANSAC（スパースマッチング）。
- **テクニック:**
    - **一般シーン:** 画像検索（NetVLAD）、回転検出、オーバーラップ検出、スパースマッチング（Superpoint + Superglue）、密なマッチング（RoMaまたはDKMv3）、信頼度ガイド付きマージ、COLMAPによる粗いSfM（2回マッピング）、反復改良。RoMaのバックボーンをvit-bに置き換えて再学習。
    - **透明シーン:** tokencutで前景セグメンテーションを実行し、前景領域がすべての画像でほぼ一貫している場合に透明シーンと判定。画像類似度行列（NetVLADまたはスパースマッチング+RANSAC）とTSPアルゴリズムに基づいて画像順序を復元。円形のカメラ軌跡を生成し、画像順序に従ってカメラ中心座標を均等にサンプリングしてカメラ姿勢を推定。

**8位**

- **アプローチ:** ALIKED+LightGlueを基本とし、画像回転への対応を強化。
- **アーキテクチャ:** ALIKED (特徴点検出器)、LightGlue (特徴点マッチング器)、COLMAP。
- **アルゴリズム:** ホモグラフィー行列を用いたアフィン変換（画像回転補正）。
- **テクニック:**
    - **キーポイント抽出（1段階目）:** 画像を90度ずつ回転させながらALIKEDでキーポイントを検出。
    - **画像マッチング（2段階目）:** 1段階目で得られたキーポイントを使用して、画像ペアの向きを補正し、再度画像マッチングを実行（LightGlue）。ホモグラフィー行列を使用して画像の向きを補正。
    - **3D再構成:** pycolmapのincrementalMappingを "simple-radial" 設定で2回、"simple-pinhole" 設定で1回実行し、最も大きなモデルを提出。
    - **高速化:** キーポイント抽出に2スレッド（各GPUに割り当て）、COLMAP処理に2フォークプロセスを使用。

**10位**

- **アプローチ:** 網羅的なペアマッチング、特徴点抽出（ALIKED, AffNet+HardNet）、特徴点マッチング（LightGlue, AdaLAM）、COLMAPによる増分マッピング。透明画像に対する特別な処理（中心クロップ）。
- **アーキテクチャ:** ALIKED, AffNet, HardNet (特徴点検出器)、LightGlue, AdaLAM (特徴点マッチング器)、COLMAP。
- **アルゴリズム:** COLMAPの増分マッピング。
- **テクニック:**
    - **画像検索:** オープンソースのベースラインのハイパーパラメータを調整し、シーン内のすべての画像ペアを網羅的にマッチング。
    - **特徴点抽出:** 回転不変な特徴点検出器（AffNet/HardNet）の使用と、軽量な向き検出器による画像ペアの回転補正を検討。最終的にはALIKED+LightGlueとAffNetの組み合わせを使用。透明画像に対しては中心クロップを実施。
    - **特徴点マッチング:** AdaLAMを使用してすべての可能なペアをマッチングし、LightGlueのマッチング結果とマージ。
    - **増分マッパー:** COLMAPの増分マッパーを使用（デフォルトパラメータをほぼ使用、ただし min_model_size を 3 に設定）。
    - **アンサンブル:** 過去の経験に基づき、異なるモデルの融合を検討したが、最終的には2モデルの融合（ALIKED+LightGlueとAffNet）の結果を提出。