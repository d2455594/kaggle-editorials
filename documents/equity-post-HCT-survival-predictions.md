---
tags:
  - Kaggle
  - 生存予測
url: 
startdate: 2024-12-05
enddate: 2025-03-06
---
# CIBMTR - Equity in post-HCT Survival Predictions
https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions

**概要 (Overview)**

* **目的:** このコンペティションの主な目的は、造血細胞移植（Hematopoietic Cell Transplantation - HCT）を受けた患者の移植後（例: 100日後）の生存確率を予測するモデルを開発することです。特に重要なのは、その予測モデルが人種や民族といった**異なる人口統計グループ間で公平（Equity）に機能する**ようにすることです。
* **背景:** HCTは血液がんなどの治療法ですが、その成功率は患者の背景によって異なる可能性があります。Center for International Blood and Marrow Transplant Research (CIBMTR) は、HCTに関する大規模なデータを収集・管理しています。従来の予測モデルが特定の人種・民族グループに対して不利な予測（バイアス）をしてしまう可能性があり、それがリスク評価や治療方針に影響を与える懸念があります。このコンペティションは、予測精度を維持しつつ、グループ間での予測性能の格差を最小限に抑える、公平なモデルの開発を目指しています。
* **課題:** 高い全体的な予測精度と、人種・民族グループ間での公平性（予測性能の均一性）という、二つの目標を同時に達成するモデルを構築することが求められます。これは、モデルの性能評価において公平性の側面を明示的に組み込む必要があることを意味します。タスクとしては、特定の時点（例: 移植後100日）での生存状態を予測する**二値分類問題**として扱われることが多いです。

**データセットの形式 (Dataset Format)**

提供される主なデータは、CIBMTRレジストリから得られた、匿名化されたHCT患者の臨床データで、表形式（CSVファイル）で提供されます。

1.  **トレーニングデータ (`train.csv` など):**
    * 個々の患者の記録を含みます。主要な列として以下のようなものが考えられます。
        * 患者の人口統計情報（年齢、**人種/民族**など）。
        * 疾患に関する情報（疾患の種類、進行度など）。
        * 移植に関する情報（ドナーの種類、移植年、HLA適合度など）。
        * **ターゲット変数:** 予測対象となる結果。例として、移植後100日時点での生存状態 (`survival_status_at_100_days`、0=死亡/1=生存 のような二値変数）が含まれます。

2.  **テストデータ (`test.csv` など):**
    * トレーニングデータと同様の形式で、患者の臨床情報が含まれますが、ターゲット変数（生存状態）は含まれません。
    * 参加者は、このテストデータに対して生存状態（または生存確率）を予測します。

3.  **`sample_submission.csv`**:
    * 提出フォーマットのサンプル。通常、`patient_id` などの識別子と、予測されたターゲット変数（例: 100日生存確率）の列を持ちます。

**評価指標 (Evaluation Metric)**

このコンペティションの評価指標は、「公平性」を重視するため、単純な予測精度だけでなく、グループ間の公平性を測る要素が組み込まれている可能性が高いです。

* **主要な予測精度指標:**
    * **Area Under the ROC Curve (AUC):** 二値分類問題（例: 100日生存/死亡）の性能を評価する標準的な指標。モデルがランダムよりもどれだけうまく陽性（生存）と陰性（死亡）を区別できるかを示します。値は0から1の範囲を取り、1に近いほど性能が良いことを示します。
* **公平性に関する評価:**
    * 評価指標には、上記の**AUCスコアが、異なる人種・民族グループ間でどれだけ均一であるか**を測る仕組みが含まれると考えられます。
    * 具体的には、全体的なAUCスコアと、各グループで計算されたAUCスコアの差（または標準偏差など）に基づいてペナルティを課すような**カスタム複合スコア**が用いられる可能性があります。目標は、高い全体AUCを維持しつつ、グループ間のAUCの差を最小化することです。
    * 正確な計算式はコンペティションの評価ページで定義されますが、「Overall AUC - Penalty based on AUC differences across groups」のような形式が想定されます。

要約すると、CIBMTRコンペティションは、HCT後の生存予測（例: 100日生存）を行う二値分類タスクであり、その性能は、全体的な予測精度（AUC）と、人種・民族グループ間での予測精度の公平性（グループ間AUCの差の小ささ）を組み合わせた複合指標によって評価されます。データは匿名化された患者の臨床情報（人種/民族情報を含む）です。

---

**全体的な傾向**

上位解法では、生存時間予測（`efs_time`）とイベント発生の有無（`efs`）を別々に扱う、**2段階のアプローチ**が主流でした。具体的には、イベント発生確率を予測する分類モデルと、イベントが発生した場合の生存時間を予測する回帰モデルを独立して学習させ、その後、これらの予測値を組み合わせて最終的なリスクスコアを算出する手法が多くのチームで採用されています。

**各解法の詳細**

**1位**

- **アプローチ:**
    - `efs == 0` の確率が高い患者には高いリスクスコアを与え、それ以外の場合は `efs_time` の順位に重点を置く。
    - 分類モデルと回帰モデルを独立して学習し、カスタム関数で結合。
- **アーキテクチャ:**
    - **分類器 (`P(efs=0)`):** XGBoost, LightGBM, CatBoost, NN, TabM, GNN, pairwise-rank-lossを用いたNN/TabNet/GNN。
    - **回帰器 (`efs == 1` での `efs_time` の正規化ランク):** XGBoost, LightGBM, CatBoost。
- **アルゴリズム:**
    - XGBoost, LightGBM, CatBoost (GBDT系アルゴリズム)
    - ニューラルネットワーク (NN)
    - TabM
    - グラフニューラルネットワーク (GNN, GraphSAGE)
- **テクニック:**
    - **特徴量エンジニアリング:** 元の特徴量、カテゴリカル変数のOne-Hotエンコーディング（元のカテゴリカル変数も保持）、連続変数をカテゴリカル変数としてコピー。
    - **CV戦略:** 10分割のStratifiedKFold（固定シード）。早期停止は使用せず、過学習のリスクを低減。
    - **分類器の工夫:**
        - KNNで近傍の25ノードを見つけ、グラフを作成し、GraphSAGEで学習。
        - ランク損失使用時の予測のずれを修正。
    - **回帰器の工夫:**
        - 学習時に `efs` を特徴量として追加し、`efs == 1` のサンプルに焦点を当てる。推論時には `efs = 1` を設定。
        - `efs == 1` と `efs == 0` のサンプルに 0.6:0.4 のサンプル重みを適用。
        - `efs == 0` のサンプルを回帰モデルの学習に含めることで、`efs == 1` の性能が向上。
    - **モデルの結合:** カスタム関数を用いて分類器の出力と回帰器の出力を結合。Optunaでハイパーパラメータを調整。
    - **アンサンブル:** 分類器と回帰器の組み合わせを作成し、最適な結合関数のパラメータを探索。Optunaで重みを最適化し、最終的な予測を生成。

**2位**

- **アプローチ:**
    - SurvivalGANの論文を参考に、`efs` の分類と `efs_time` の回帰を分離。
    - 回帰モデルでは `efs` を追加の特徴量として使用し、推論時には `efs = 1` を設定。
    - 分類モデルと回帰モデルの予測値を組み合わせてリスクスコアを算出。
    - 評価指標を直接最適化するニューラルネットワークも学習。
- **アーキテクチャ:**
    - **回帰器 (`efs == 1` での `efs_time`):** XGBoost, HistGBM。
    - **分類器 (`efs`):** RealMLP, HistGBM, CatBoost。
    - **直接的なリスクスコア予測:** ニューラルネットワーク (回帰モデルの予測値を入力として使用)。
- **アルゴリズム:**
    - XGBoost, HistGBM, CatBoost (GBDT系アルゴリズム)
    - RealMLP (多層パーセプトロン)
    - ニューラルネットワーク
- **テクニック:**
    - **特徴量エンジニアリング:** 分類モデルでは特徴量エンジニアリングなし。回帰モデルでは `efs` を特徴量として追加。
    - **回帰の工夫:** 推論時に `efs = 1` を設定することで、イベントが発生した場合の生存時間を推定。
    - **モデルの結合:** 分類モデルの予測確率と回帰モデルの予測値を組み合わせてリスクスコアを算出 (`R = p(efs=1) * p(efs_time | efs=1)`)。
    - **直接的なリスクスコア予測:** カスタム損失関数を用いて、評価指標を近似的に最適化するニューラルネットワークを学習。
    - **アンサンブル:** メインのパイプラインと直接的なリスクスコア予測を行うニューラルネットワークの予測値をランクアンサンブル。
    - **AutoGluonの利用:** 自動機械学習ライブラリAutoGluonでも高いスコアを達成。
    - **事後処理:** 分類器の出力をカスタムシグモイド関数でキャリブレーション。

**3位**

- **アプローチ:**
    - 検証戦略を重視し、4分割CVを複数のランダムシードで評価。
    - `efs = 1` の観測値には [0, 1] の一様分布のターゲット、`efs = 0` の観測値には [1.345, 1.355] の固定範囲のターゲットを設定（人種グループごとに計算）。
    - `efs = 1` と `efs = 0` のクラスに属する確率で重み付けされた、uncensoredデータとcensoredデータ内での個別の回帰を実行。
- **アーキテクチャ:**
    - **回帰器:** CatBoost, LightGBM, XGBoost, MLP with ODST, TabM。
    - **分類器:** CatBoost, LightGBM, XGBoost, MLP with ODST, TabM (NNが最も性能が良い)。
- **アルゴリズム:**
    - CatBoost, LightGBM, XGBoost (GBDT系アルゴリズム)
    - 多層パーセプトロン (MLP) with ODST
    - TabM
- **テクニック:**
    - **検証戦略:** 安定したCV-LB相関を確保するために、複数のランダムシードを用いたCVを実施。
    - **ターゲットエンジニアリング:** `efs` の値に応じて異なるターゲット範囲を設定。
    - **タスクの分割:** uncensoredデータとcensoredデータに対して個別の回帰モデルを学習。
    - **損失関数の工夫:** 回帰タスクに二値交差エントロピー損失を使用。
    - **ノイズ除去:** 固定ハイパーパラメータ/アーキテクチャのモデルを複数の初期化シードで平均化。大きな回帰誤差を持つ観測値を学習データから除去（分類では過学習につながるため実施せず）。
    - **アンサンブル:** 回帰モデルを凸結合でブレンド、分類モデルをロジスティック回帰でスタッキング。ブレンドの重みは、複数のOOF予測に基づいてベイズ最適化で同時に最適化。

**4位**

- **アプローチ:**
    - 完璧な解は、イベントなしの患者をリストの一番下に、イベントありの患者をイベント時間で順位付けすることに着目。
    - イベント確率の予測と、イベントが発生した患者の中での順位の予測という2つの部分に問題を分割。
    - これらの予測値を組み合わせてリスクスコアを算出。
- **アーキテクチャ:**
    - **イベント確率予測 (`P(event)`):** TabM, CatBoost, XGBoost (二値分類)。
    - **イベント発生時の順位予測 (`E[rank% | event = 1]`):** TabM, CatBoost, XGBoost (回帰)。
- **アルゴリズム:**
    - TabM
    - CatBoost
    - XGBoost
- **テクニック:**
    - **モデルの定式化:** カスタム数式を用いてリスクスコアを計算。
    - **イベント確率予測の工夫:** censoredデータを部分的な観測として扱い、Kaplan-Meier推定量から計算された累積密度に基づいて重み付け。
    - **順位予測の工夫:** ターゲットをランクパーセント（`rank(-time)/N`）とし、逆正規累積分布関数で変換（"z-score"）、予測後に正規累積分布関数で逆変換。
    - **アンサンブル:** 個々のモデルの予測値を重み付き和で結合（イベント確率と順位予測で異なる重みを使用）。

**5位**

- **アプローチ:**
    - `efs` ラベルを予測するモデルAと、`efs == 1` の場合の `efs_time` のランクを予測するモデルBという2つのターゲットを使用。
    - カスタム数式 `P = (a * b) - ((1 - a) * (S_RATIO))` で最終予測を計算。
    - ネルソンアーレン推定量に基づいた多様な1次元ターゲットも使用。
- **アーキテクチャ:**
    - **モデルA (分類):** LGB, CatBoost, TabM, ODST Pairwise NN, AutoGluon (主にXGBoostとシンプルなNNを含む)。
    - **モデルB (回帰):** LGB, CatBoost, TabM, AutoGluon (主にXGBoostとシンプルなNNを含む)。
- **アルゴリズム:**
    - LightGBM (LGB)
    - CatBoost
    - TabM
    - ODST Pairwise NN
    - XGBoost (AutoGluon経由)
    - ニューラルネットワーク (NN) (AutoGluon経由)
- **テクニック:**
    - **ターゲットエンジニアリング:**
        - モデルAでは、`efs_time` が閾値（EFS_SPLIT = 13.326）より小さい場合に `efs == 1` となる確率を予測。
        - モデルBでは、`efs == 1` かつ `efs_time` が閾値より小さいデータのみを使用し、ランクを [0.03, 0.97] の範囲に均等に分布させ、ロジット変換した値をターゲットとして回帰。
        - ネルソンアーレン推定量に基づいた多様な1次元ターゲットを作成し、`efs == 0` のデータの扱い方（シフト、スケーリング、サンプル重み）を様々に変更。
        - Andrewの公開ノートブックのCox損失も使用（ただし、事後処理としてロジットから確率に変換）。
        - ODST Pairwise NNは直接コンコルダンス指標を最適化。
    - **特徴量エンジニアリング:** GBDTモデルではHLA関連の特徴量を再計算、NNモデルではHLA関連の特徴量を削除するなど、モデルタイプによって異なる特徴量エンジニアリングを実施。
    - **学習方法:** LGBは手動チューニング、CatBoostはAutoGluonと公開ノートブックのパラメータを使用、TabMは公開ノートブックをベースにチューニング（Cosine LR with Warm Restarts）、ODST Pairwise NNは固定エポック数で学習（SWA使用）、AutoGluonは多数のモデルとハイパーパラメータプリセットを使用。
    - **アンサンブル:** Greedy Ensemble Selection (GES) のカスタムバリアントを使用。モデルAとモデルBを個別にアンサンブルし、その後結合。

**6位**

- **アプローチ:**
    - `efs == 1` の確率と、イベント発生時の期待生存時間をGBDTモデルで予測。
    - 評価指標の滑らかなバージョン（シグモイド関数を使用）を最適化するTabMニューラルネットワークを学習。
    - これらの予測値を組み合わせて最終的なリスクスコアを算出。
- **アーキテクチャ:**
    - **GBDTモデル:** イベント確率予測と期待生存時間予測にGBDTモデルを使用（具体的なアルゴリズムは不明）。
    - **ニューラルネットワーク:** TabM。
    - **メタモデル:** 単層ニューラルネットワーク（非線形性なし）。
- **アルゴリズム:**
    - GBDT (具体的なアルゴリズムは不明)
    - TabM
    - ニューラルネットワーク
- **テクニック:**
    - **2段階モデリング:** イベント確率と生存時間を別々に予測。
    - **評価指標の近似:** ニューラルネットワークで評価指標の滑らかなバージョンを最適化。
    - **クロスバリデーション:** 全てのモデルで5つのランダムシードを用いた20分割クロスバリデーションを実施。
    - **メタモデリング:** OOFデータを用いて、TabMモデルの出力とGBDTモデルの予測値の2次多項式特徴量を入力とする単層ニューラルネットワークを学習。

**9位**

- **アプローチ:**
    - `efs = 1` のデータでモデルを学習し、その予測値に `efs` が1になる確率を掛けて最終的な予測とする。
- **アーキテクチャ:**
    - 具体的なモデルアーキテクチャは不明。
- **アルゴリズム:**
    - 具体的なアルゴリズムは不明。
- **テクニック:**
    - `efs = 1` のデータのみで学習したモデルの予測値を、`efs` が1になる確率で調整するシンプルな手法。

