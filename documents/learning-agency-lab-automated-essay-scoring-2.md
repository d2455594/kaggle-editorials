---
tags:
  - Kaggle
  - テキスト生成
  - NLP
startdate: 2024-04-04
enddate: 2024-07-03
---
# Learning Agency Lab - Automated Essay Scoring 2.0
https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2

**概要 (Overview)**

* **目的:** このコンペティションの目的は、学生が書いたエッセイ（小論文）に対して、人間が行う評価と同様の精度で自動的に総合スコア（評点）を付与する機械学習モデル（Automated Essay Scoring - AES システム）を開発することです。"2.0" という名称は、以前のAESコンペティションからの発展や、より高度な技術（例: 大規模言語モデルの活用）の利用を示唆している可能性があります。
* **背景:** AESシステムは、学生への迅速なフィードバック提供や、教育者の採点業務の負担軽減に貢献する可能性があります。しかし、エッセイの質（構成力、論理性、表現力、文法など）の微妙なニュアンスを捉え、公平かつ信頼性の高い評価を行うシステムの開発は依然として挑戦的な課題です。Learning Agency Lab（教育関連の研究機関と推測される）が主催するこのコンペティションは、AES技術の精度向上と発展を目指しています。
* **課題:** エッセイの品質という複雑で主観的な要素をモデル化すること、開発したモデルが異なる課題（プロンプト）やトピック、多様な学生集団に対しても頑健に機能（汎化）すること、そして特定の書き方や背景に対するバイアスを回避することが課題となります。タスクは、エッセイのテキストを入力として、事前に定義された尺度（例: 1点から6点の整数）上の総合スコアを予測する**回帰問題**または**順序分類問題**として扱われます。

**データセットの形式 (Dataset Format)**

提供される主なデータは、学生が書いたエッセイのテキストとその評価スコアで、主に表形式（CSVファイル）で提供されます。

1.  **トレーニングデータ (`train.csv` など):**
    * 各行が一つのエッセイに対応します。
    * 列には通常、以下が含まれます。
        * `essay_id`: 各エッセイの一意な識別子。
        * `full_text`: エッセイの本文テキスト。
        * `score`: **予測対象のターゲット変数**。人間（または複数の人間の評価者）によって付けられた総合スコア（整数値）。
    * もし複数の課題（プロンプト）に対するエッセイが含まれる場合、どのプロンプトに対応するかの情報 (`prompt_id` など) が含まれることもあります。

2.  **テストデータ (`test.csv` など):**
    * トレーニングデータと同様に `essay_id` と `full_text` を含みますが、`score` 列は含まれません。
    * 参加者は、このテストデータに含まれるエッセイに対してスコアを予測します。

3.  **`sample_submission.csv`**:
    * 提出フォーマットのサンプル。通常、`essay_id` と、予測された `score` の列を持ちます。

**評価指標 (Evaluation Metric)**

* **指標:** **Quadratic Weighted Kappa (QWK) (二次加重カッパ係数)**
* **計算方法:** QWKは、2つの評価者（この場合はモデルの予測スコアと人間の付けた正解スコア）間の一致度を測定する指標です。偶然による一致を除外した上で、予測スコアと正解スコアの差が大きいほどペナルティが重くなるように重み付け（二次加重）されています。
    * スコアの範囲は通常 -1 から 1 です。
        * 1: 完全一致
        * 0: 偶然期待される一致度
        * 負の値: 偶然期待されるよりも不一致
* **意味:** QWKは、自動採点システムが人間の評価者とどれだけ一貫したスコアを付けられているかを評価するために、AESタスクで標準的に用いられる指標です。単なる正解率ではなく、スコアの誤差の大きさを考慮するため、評価の質をより実態に近く測ることができます。QWKの値が**高い**（1に近い）ほど、モデルの採点精度が高いと評価されます。

要約すると、このコンペティションは、学生のエッセイテキストからその総合スコアを予測する自動エッセイ採点（AES）タスクです。データはエッセイテキストと対応するスコアから成り、性能は人間の評価との一致度を誤差の大きさを考慮して測るQuadratic Weighted Kappa (QWK、高いほど良い) によって評価されます。

---

**全体的な傾向**

上位解法では、Transformerベースの言語モデル（特にDeBERTa）のアンサンブルが主流でした。データセットの特性（Persuade Corpus 2.0とKaggle-onlyデータ）を考慮した学習戦略や、疑似ラベリング、閾値最適化などが重要なテクニックとして用いられました。

**各解法の詳細**

**1位**

- **アプローチ:** CV（交差検証）とLB（リーダーボード）を信頼し、データ分析と実験に基づいて新しいデータ採点パターンを発見。それらのスコアを反映したDeBERTaアンサンブルを訓練。2段階の疑似ラベリングを実施し、「古い」データを「新しい」スコアで再学習。浮動小数点予測を閾値処理により整数に変換。オーバーフィットを避けたアンサンブル。
- **アーキテクチャ:** DeBERTa large、DeBERTa baseのアンサンブル。
- **アルゴリズム:** MSE損失、Binary Cross-Entropy損失、AdamWオプティマイザ、コサイン減衰スケジューラ。Nelder-Mead法、Powell法（閾値探索）。
- **テクニック:**
    - **CV-LB相関の獲得:** 新旧データの採点基準の違いを分析し、2段階学習（古いデータで事前学習、新しいデータでファインチューニング）を実施。
    - **DeBERTaの訓練:** 異なるプーリング方法、損失関数、コンテキスト長などを試行し、多様なモデルを生成。3シード平均化による安定化。
    - **疑似ラベリング:** 新しいデータでファインチューニングしたアンサンブルを用いて古いデータを疑似ラベル化（2ラウンド）。
    - **閾値処理:** 浮動小数点予測を整数スコアに変換するための閾値を探索（`minimize` 関数とPowell法を使用）。アンサンブルの重みにも閾値を適用。
    - **アンサンブル:** 単純平均、Nelder-Mead法、Hill-climbing法。

**2位**

- **アプローチ:** 2段階学習（Kaggle-Persuadeで事前学習後、Kaggle-Onlyでファインチューニング）。MLM（Masked Language Modeling）による事前学習。最適な閾値を探索し、モデルをアンサンブル。
- **アーキテクチャ:** DeBERTa-v3-largeを主に使用。
- **アルゴリズム:** BCEWithLogitsLoss（順序回帰）、MSE損失。
- **テクニック:**
    - **2段階学習:** テストセットと類似性の高いKaggle-Onlyデータでファインチューニング。
    - **MLM:** 全学習データで10エポックのMLM事前学習。
    - **CV:** 4分割SKF。Kaggle-PersuadeとKaggle-Onlyの両データで検証。
    - **閾値探索:** OptimizedRounderを使用し、最終閾値を調整。Kaggle-Onlyデータのみで閾値を探索する実験も実施。
    - **モデル:** 順序回帰、Petモデル（prompt tuning）、文埋め込みの平均プーリングなど、多様なモデルを試行。
    - **アンサンブル:** 投票アンサンブル。

**3位**

- **アプローチ:** 競技データとPersuade Corpus 2.0の利用を重視。2段階学習（全データで事前学習後、競技データに焦点を当ててファインチューニング）。ソフトラベリング、MLM事前学習、レイヤー凍結。
- **アーキテクチャ:** DeBERTa-v3-base、DeBERTa-v3-largeを主に使用。
- **アルゴリズム:** BCE損失、AdamWオプティマイザ。
- **テクニック:**
    - **データ利用:** 競技データとPersuade Corpus 2.0を区別して分析し、競技データに焦点を当てた学習戦略を採用。
    - **データ前処理:** 改行文字を特殊トークンに変換。
    - **CV戦略:** Prompt name/scoreに基づいたMultilabelstratifiedkfold。Data AとData Bを別々に分割。
    - **モデルと学習:** MLM事前学習とレイヤー凍結（9層または6層）。回帰とBCE損失を使用。2段階学習でソフトラベリングを活用。
    - **アンサンブル:** Nelder-Mead法を用いた単純なアンサンブル。

**4位**

- **アプローチ:** Persuadeデータと非Persuadeデータの非互換性を考慮。テストサンプルは全て非Persuadeデータであると仮定。データソースのタグ付け、データソース分類ヘッドの追加、非Persuadeデータのスコアに基づく早期停止。
- **アーキテクチャ:** DeBERTa-large、DeBERTa-v3-large、Qwen2-1.5B-Instructのアンサンブル。
- **アルゴリズム:** AdamWオプティマイザ。
- **テクニック:**
    - **データソースの区別:** 入力にデータソースのタグを追加。データソース分類ヘッドを追加。一部モデルではデータソースごとに異なる分類ヘッドを使用。
    - **早期停止:** 非Persuadeデータのスコアに基づいて早期停止。
    - **提出:** 全てのサンプルを非Persuadeデータとして扱う。
    - **その他:** 疑似ラベリングと蒸留のためのタグのスワップを試行。動的マイクロバッチ照合、高速なDeBERTa実装。

**5位**

- **アプローチ:** Kaggle-onlyデータとPersuade 2.0データを用いた2段階ファインチューニング。DeBERTaモデルとLGBMのブレンド。
- **アーキテクチャ:** DeBERTa (small/base/large)、LightGBM。
- **アルゴリズム:** LightGBM。
- **テクニック:**
    - **データ分割:** Kaggle-onlyデータをStratifiedKFoldで分割。
    - **ファインチューニング:** Persuade 2.0データとKaggle-onlyデータでDeBERTaモデルをファインチューニング。その後、Kaggle-onlyデータのみで再学習。
    - **ブレンド:** DeBERTaモデルの予測とLGBMの予測を重み付け平均（0.9:0.1）。

**6位**

- **アプローチ:** LBプロービングとデータ分析に基づいた検証戦略。`persuade` フラグの追加、テストセットのみで学習したVectorizerの利用、DeBERTaの最大推論長の増加、DeBERTa OOFのCDF変換、外部特徴量の追加、リラベリング。
- **アーキテクチャ:** DeBERTa-v3-large、LightGBM。
- **アルゴリズム:** TfidfVectorizer、CountVectorizer。
- **テクニック:**
    - **検証:** テストセットのトピック分布を推定し、それに基づいて検証データの重みを調整。`persuade` フラグを特徴量として追加。
    - **特徴量エンジニアリング:** テストセットのみでVectorizerを学習。DeBERTa OOFをCDFに変換。texstatとspaCyベースの特徴量を追加。
    - **リラベリング:** DeBERTaの予測と実際のラベルの差が大きい場合にラベルを修正。

**7位**

- **アプローチ:** 強力な公開ノートブックをベースに改善。Persuade 2.0の理解、Kaggle-onlyデータの重複、ハイパーパラメータ調整。
- **アーキテクチャ:** DeBERTa-v3-largeベースのLGBM。
- **アルゴリズム:** LGBM。
- **テクニック:**
    - **データ理解:** Persuade 2.0とKaggle-onlyデータの特性を分析。
    - **データ重複:** Kaggle-onlyデータを重複させて学習データを強調。ただし、リークを防ぐためにCVで工夫。
    - **ハイパーパラメータ調整:** LGBMのハイパーパラメータを探索的に調整。学習時のQuadratic Weighted Kappaのa, b値を調整。推論時のa値も調整。