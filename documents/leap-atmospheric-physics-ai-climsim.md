---
tags:
  - Kaggle
  - 気象
startdate: 2024-04-19
enddate: 2024-06-16
---
# LEAP - Atmospheric Physics using AI (ClimSim)
https://www.kaggle.com/competitions/leap-atmospheric-physics-ai-climsim

**概要 (Overview)**

* **目的:** このコンペティションの目的は、気候モデル（Climate Model）内で用いられている、計算コストの高い**大気物理過程のパラメタリゼーション**（物理法則に基づく近似計算）を、高速かつ正確に**模倣（エミュレート）する機械学習モデル**を開発することです。具体的には、ClimSimと呼ばれる気候シミュレーションデータセットが利用されます。
* **背景:** 気候モデルは地球の気候システムをシミュレーションしますが、雲の形成や放射過程など、モデルの解像度よりも小さいスケールで起こる物理プロセスは「パラメタリゼーション」と呼ばれる手法で近似的に扱われます。これらの計算は気候モデル全体の計算時間のかなりの部分を占めるため、AIを用いた高速なエミュレータで置き換えることができれば、気候シミュレーションの大幅な高速化が期待されます。LEAP (Learning the Earth with AI and Physics) は、AIと物理学を融合させて地球科学の進歩を目指すイニシアチブです。
* **課題:** 元のパラメタリゼーションが表現する複雑で非線形な物理プロセスの振る舞いを、データ駆動型の機械学習モデルで忠実に再現することが求められます。開発されたエミュレータは、精度が高いだけでなく、物理的に妥当であり、安定して動作する必要があります。タスクは**回帰問題**として定義され、特定地点・時刻の大気の状態（入力変数）から、物理パラメタリゼーションが計算するであろう変化率（出力変数）を予測します。

**データセットの形式 (Dataset Format)**

提供される主なデータは、気候モデル（ClimSim）によって生成された、大規模な大気の状態とそれに対応する物理パラメタリゼーションの出力データです。

1.  **入力データ:**
    * あるグリッドセル（モデル内の特定の場所と高度）および時刻における大気の状態を表す変数。
        * 例: 温度、比湿、気圧などの鉛直プロファイル（異なる高度での値）。
    * ファイル形式は、気候科学分野で標準的な **NetCDF (`.nc`)** や、大規模データに適した Zarr、Parquet などが考えられます。

2.  **出力データ（ターゲット変数）:**
    * 上記の入力状態に対応して、元の物理パラメタリゼーション（雲、放射、乱流など）が計算した出力値または傾向（Tendency: 単位時間あたりの変化率）。
        * 例: 放射による加熱率、対流による水蒸気量の変化率など、多数の物理量。
    * 入力データと同じく、NetCDF 等の形式で提供され、入力データとサンプル（グリッドセル・時刻）が対応付けられています。

3.  **ファイル構造:**
    * `train_inputs.nc`, `train_outputs.nc`, `test_inputs.nc` のような、入力と出力が分かれた大規模なファイル群として提供されることが想定されます。
    * `sample_submission.csv` は、テストデータの各サンプルIDに対して、予測すべき全てのターゲット変数の値を記述する形式を示します。
    * 変数の詳細な説明や単位などを記載したメタデータも提供されます。

**評価指標 (Evaluation Metric)**

* **指標:** **Root Mean Squared Error (RMSE) に基づくカスタムスキルスコア** (複数のターゲット変数にわたって平均化されることが多い)
* **計算方法:**
    1.  まず、各ターゲット変数（物理的な変化率など）について、モデルの予測値と真の値との間の **RMSE** を計算します。
        RMSE = sqrt [ Σ (予測値 - 真の値)² / N ]
    2.  次に、各変数について、モデルのRMSEを何らかのベースライン（例: 常にゼロ変化を予測する、前の値を維持するなど）のRMSEと比較して**スキルスコア**を算出します。スキルスコアは、モデルがベースラインよりどれだけ改善したかを示し、例えば `1 - (RMSE_model / RMSE_baseline)` のような形式を取ることがあります。（完全な予測でRMSEが0ならスキルスコアは1、ベースラインと同じなら0、ベースラインより悪ければ負の値になります）。
    3.  最後に、全てのターゲット変数について計算されたスキルスコアを（場合によっては物理的な重要度などで重み付けして）**平均**したものが、最終的な評価スコアとなります。
* **意味:** この指標は、単に予測誤差の絶対値を測るだけでなく、予測が難しいとされる物理プロセス（ベースラインからの改善が難しい変数）の予測精度も評価に反映させ、AIエミュレータが元のパラメタリゼーションを全体としてどれだけ「うまく」模倣できているかを測ります。スキルスコアが**高い**（理想的には1に近い）ほど、性能が良いと評価されます。

要約すると、LEAP (ClimSim) コンペティションは、気候モデルの大規模シミュレーションデータを用いて、大気物理パラメタリゼーションを模倣するAIエミュレータ（回帰モデル）を開発するタスクです。データはNetCDFなどの形式で提供され、性能は複数の物理変数に対する予測精度をRMSEベースのカスタムスキルスコア（高いほど良い）で評価されます。

---

**全体的な傾向:**

このコンペでは、気象シミュレーションの出力を予測することが課題であり、時系列データモデリングが中心となります。上位解法では、Transformer、LSTM、CNN、Squeezeformerなどの様々なニューラルネットワークアーキテクチャが用いられています。データの正規化、特徴量エンジニアリング（特に物理法則に基づいた特徴量）、損失関数の工夫（MAE、Smooth L1 Loss、補助損失）、アンサンブル学習などが重要なテクニックとして活用されています。大規模なデータセット（Hugging FaceのLEAPデータ）の利用も一般的です。

**各解法の詳細:**

**1位**

- **アプローチ:** Squeezeformerをベースとしたモデル。MAE損失、補助損失（時空間情報）、信頼性ヘッド、マスクされた損失を使用。複数のデータ表現、高解像度データ、ソフトクリッピングなどのデータ準備も重要。
- **アーキテクチャ:** Squeezeformer（修正版、ECAレイヤー追加）、GLUMlp予測ヘッド。
- **アルゴリズム:** AdamWオプティマイザ、ハーフコサイン減衰スケジューラ。
- **テクニック:**
    - **モデル:** 12ブロックのSqueezeformerモデル（次元数256/384/512）。
    - **損失関数:** MAE（平均絶対誤差）、補助損失（正規化された緯度/経度、年周期のsin/cos）、信頼性ヘッド（損失を予測）、マスクされた損失。
    - **データ準備:** 高解像度データを使用（低解像度とブレンド）、複数のデータ表現（特徴量ごとに異なる正規化）、風速特徴量、特徴量とターゲットのソフトクリッピング。
    - **後処理:** ダウンキャストとアップキャスト、不良ターゲットの平均値で置換、ptendトリック。
    - **検証:** ランダムに選択された低解像度および高解像度データの複数の検証セット。公開LBに対するアンサンブル検証。
    - **アンサンブル:** 13モデルのアンサンブル（それぞれわずかに異なる）。

**2位**

- **アプローチ:** 1D seq2seqマルチターゲット回帰タスクとして問題を捉え、様々なモデル構造を訓練し、検証セットのスコアに基づいてヒルクライミングアルゴリズムでアンサンブル。
- **アーキテクチャ:** ResLSTM、GF-ResLSTM、GF-CNN-LSTM、GF-LSTM-Mamba、GF-LstmMambaMixedなど、主にLSTMベースの様々なモデル。
- **アルゴリズム:** Smooth L1損失、補助Diff損失、コサインアニーリングスケジューラ、AdamWオプティマイザ。
- **テクニック:**
    - **データ:** Hugging Faceの低解像度データセット全体を使用。
    - **クロスバリデーション:** 最初の7年と8年目の前半（約7500万データポイント）で訓練。8年目の後半と9年目の1月をホールドアウト検証セット（約625000データポイント）として使用。
    - **モデル最適化:** Smooth L1損失、補助Diff損失（隣接レベルの差分）、コサインアニーリングスケジューラ。
    - **グループファインチューニング:** 368の特徴量を7つのグループに分け、フル出力で訓練後、各グループを再度ファインチューニング（1エポック）。
    - **後処理:** 標準偏差と平均で非正規化。ptend_q0002の特定変数を線形関係に基づいて調整。公式のサンプル提出ファイルの重み値を適用。
    - **アンサンブル:** ヒルクライミング法でブレンド重みを探索。

**3位**

- **アプローチ:** 各チームメンバーが個別のニューラルネットワークモデルを構築し、Camaroモデルの予測に対してGBDT回帰器で予測を洗練。最終予測はこれらの予測の重み付き平均。
- **アーキテクチャ:**
    - **Pao:** 1D CNN + Transformer + LSTM。
    - **Camaro:** CNNとTransformerの組み合わせ、またはTransformerのみ（CLIPエンコーダを使用）。
    - **Kmat:** FiLM 1D UNet。
- **アルゴリズム:** 1D CNN、Transformer、LSTM、FiLM、LightGBM（2ndステージ）。Huber損失、KLダイバージェンス損失、対照損失、BCE損失。AdamW、Adam。
- **テクニック:**
    - **Pao:** 元の特徴量と相対湿度、高さ方向の1次微分と2次微分。隣接する垂直レベル間の差を予測する補助損失。Row-lessフルトレーニング。
    - **Camaro:** フルデータセットと長時間のトレーニング。飽和水蒸気圧を特徴量として追加。隣接する垂直レベル間の差を予測する補助損失。
    - **Kmat:** 差分特徴量、相対湿度関連の特徴量。複数の正規化方法。温度、q000X、風ベクトル予測のための3つのヘッドブランチを持つFiLM 1D UNet。state_qドロップの分類ブランチ。
    - **2ndステージ:** LightGBMでptend_qを予測。
    - **アンサンブル:** 重み付き平均。Nelder-Meadを使用。1D-CNNスタッキング。

**4位**

- **アプローチ:** 複数のConvNeXtモデルとTransformerモデルのアンサンブル。特徴量エンジニアリングと前処理、2段階学習戦略。
- **アーキテクチャ:** ConvNeXt（1D入力向けに修正）、Transformer。
- **アルゴリズム:** AdamWオプティマイザ、Polynomial Decay Scheduler、WarmupDecayLR。SmoothL1Loss。
- **テクニック:**
    - **特徴量エンジニアリング:** 差分特徴量、類似特徴間の平均と差分平均。
    - **前処理:** 特徴量とラベルにStandardScalerを適用（train/test両データで計算）。極端な値をクリップ。スカラー値を時間シリーズデータに変換。
    - **学習:** 7エポック（ConvNeXt）、4エポック（Transformer）。投票数の少ないデータで初期学習、その後投票数の多いデータでファインチューニング。
    - **後処理:** 特定の値を `state * (1 / -1200)` に設定。
    - **アンサンブル:** 複数のConvNeXtモデルとTransformerモデルの重み付き平均。

**5位**

- **アプローチ:** 双方向LSTMベースのモデルのアンサンブル。各モデルは独自のバリエーションを持つ。
- **アーキテクチャ:** MLPエンコーダ・デコーダ、双方向LSTM（3-6層）、双方向GRU、FFNN。
- **アルゴリズム:** Huber損失。
- **テクニック:**
    - **データ前処理:** 低解像度とaqua-planetデータを混合、または低解像度と一部の高解像度データを混合。特徴量のエンジニアリング（liq_partition, imbalance, moisture, air_total, temp_humid, temp_diff, wind_diffなど）。入力と出力の標準化、一部入力の対数変換。
    - **モデル:** ワイド（隠れ層512）だが浅い（3層）双方向LSTM、単一の双方向GRU層、最終MLPエンコーダ。または、線形層で入力次元を拡張、深い（6層）双方向LSTM、1D平均プーリング層、平均層、連結、線形層のシーケンス。
    - **学習:** バッチサイズ4-5ファイルまたは4000-5000データポイント。Huber損失（delta=1）。単一モデルを混合データで最後まで訓練し、その後、わずかに異なる手順で同じモデルをファインチューニングして、効果的にアンサンブルできる個別のモデルを作成。低解像度と高解像度データを混合したモデルは、低解像度データと高解像度データのバッチをモデルで評価し、損失は低解像度データと高解像度データの損失の重み付き組み合わせ。
    - **アンサンブル:** 実験的に最適な重みを決定。

**7位**

- **アプローチ:** LSTM、Transformer、Conv1D、Squeezeformerを含む様々なモデルを使用。ドメイン知識に基づく追加特徴量。MAEまたはSmoothL1Lossで訓練後、MSEで追加訓練。Nelder-Mead法で最適化された重みによる重み付き平均アンサンブル。
- **アーキテクチャ:** Transformer + LSTM、LSTM、Conv1D、Squeezeformer。
- **アルゴリズム:** MAE、SmoothL1Loss、MSE、AdamW。コサインスケジューラ。
- **テクニック:**
    - **データ準備:** Hugging Faceの低解像度データセット全体を使用。差分特徴量、相対湿度比率、圧力差、水蒸気圧、氷率などの追加特徴量。
    - **モデル:** 畳み込み特徴抽出器、位置エンコーディング、Transformerエンコーダ、双方向LSTMブロック、ResNetブロック。
    - **損失:** MAEを使用し、重みが0のターゲット列とptend_q0002_[12, 26]のターゲット列をマスク。MSEによるファインチューニング。
    - **後処理:** ptend_q0002_[12, 26]に特定の後処理を適用。state_q0002/q0003が閾値以下の場合に追加の後処理。
    - **アンサンブル:** Nelder-Mead法で最適化された重みによる重み付き平均。

**8位**

- **アプローチ:** 主にBiLSTMから派生したseq2seqモデル。モデルのアンサンブルとターゲットのアンサンブル。
- **アーキテクチャ:** BiLSTM（6-8層）、BiGRU（8層）、BiLSTM+Transformer、BiLSTM+Attention、BiLSTM+TCN、BiLSTM+CNN。
- **アルゴリズム:** AdamWオプティマイザ、コサインアニーリングスケジューラ。SmoothL1Loss。
- **テクニック:**
    - **データ:** 最後の6ヶ月のサンプルデータで検証。
    - **モデル:** 基本的なBiLSTMモデルをベースに、Transformer、Attention、TCN、CNNなどを追加したバリエーション。
    - **アンサンブル:** モデルのアンサンブル（重み付き平均）とターゲットのアンサンブル。

**10位**

- **アプローチ:** 各メンバーの回帰モデルのアンサンブル。異なるアーキテクチャと学習条件を持つ23のモデル。
- **アーキテクチャ:** Conv + Transformer (+ LSTM)、CNN / U-Net、LSTM。
- **アルゴリズム:** 1-MSE損失（標準化されたターゲットの後）、AdamWオプティマイザ、コサインアニーリングスケジューラ。
- **テクニック:**
    - **データ:** 1-7年または1-8年の低解像度データを使用。一部モデルは高解像度データや疑似ラベルデータも使用。
    - **評価指標:** 1-MSEを使用（R2の代わりに）。
    - **モデル設計 (Bilzard):** Climate-invariant特徴量（相対湿度、プルーム浮力、正規化された熱フラックスなど）の抽出。信頼性認識MSE損失。ハードサンプルのドーピング。Conv-TransformerとPixel-ShuffleスタックUNet。Tanh正規化。ドロップアウトの削除。
    - **モデル設計 (Tereka):** Transformer + Convolution + LSTM。Learnable Positional Embedding。
    - **モデル設計 (Phalanx):** CNNとTransformer。
    - **モデル設計 (Ryches):** TBD。
    - **アンサンブル:** ツリー型のアンサンブル手法と、手動で調整された重みによる最終的な重み付きアンサンブル。ターゲットごとのアンサンブル重みを学習。