---
tags:
  - Kaggle
  - 物体検出
  - セグメンテーション
  - 画像認識処理
startdate: 2024-11-07
enddate: 2025-02-06
---
# CZII - CryoET Object Identification
https://www.kaggle.com/competitions/czii-cryo-et-object-identification

**概要 (Overview)**

* **目的:** このコンペティションは、クライオ電子線トモグラフィー（Cryo-Electron Tomography, CryoET）によって得られた3次元画像（トモグラム）の中から、特定の高分子複合体や細胞小器官などの「オブジェクト」を自動で識別し、その位置を特定するモデルを開発することを目的としています。
* **背景:** CryoETは、細胞や組織を急速凍結し、電子顕微鏡で撮影した多数の傾斜画像から3次元構造を再構成する技術です。これにより、細胞内の構造を生に近い状態で高解像度に観察できますが、得られるトモグラムはノイズが多く、内部構造が非常に密集・複雑であるため、目的のオブジェクトを見つけ出す作業は専門家にとっても時間がかかり、ボトルネックとなっています。このコンペは、Chan Zuckerberg Initiative Imaging (CZII) による支援のもと、この課題に対する機械学習を用いた解決策の開発を促進することを目的としています。
* **課題:** 参加者は、ノイズが多く複雑な3Dトモグラムデータの中から、指定された複数のクラスのオブジェクト（タンパク質複合体など）を検出し、その3次元座標を正確に予測することが求められます。これは3次元オブジェクト検出（3D Object Detection）タスクに相当します。

**データセットの形式 (Dataset Format)**

提供される主なデータは以下の通りです。

1.  **トレーニングデータ:**
    * **3Dトモグラム:** CryoETから再構成された3次元のグレースケール画像ボリューム。各トモグラムは細胞の一部を含んでいます。ファイル形式はMRC (`.mrc`) など、この分野で標準的な形式か、あるいはKaggleで扱いやすいようにTIFFスタックやZarr形式などで提供される可能性があります。
    * **アノテーション:** 各トレーニング用トモグラムに含まれるオブジェクトに関する情報。通常、オブジェクトの種類（クラスラベル）とその3次元座標（x, y, z）がリストになったCSVファイルなどで提供されます。
    * *ファイル構造:* `train/`ディレクトリ内に各トモグラムIDのサブディレクトリやファイルがあり、それとは別にアノテーション情報を含む `train_annotations.csv` のようなファイルが存在する形式が考えられます。

2.  **テストデータ:**
    * トレーニングデータと同様の形式の3Dトモグラムが含まれますが、オブジェクトのアノテーションは提供されません。
    * 参加者は、これらのテスト用トモグラムに対してオブジェクトのクラスと3次元座標を予測します。

3.  **`sample_submission.csv`**:
    * 提出フォーマットのサンプル。通常、`run_id` (あるいは `tomogram_id` など) と、予測されたオブジェクトの情報（クラスID、x, y, z 座標、確信度スコアなど）を特定の形式で記述する列が含まれます。

**評価指標 (Evaluation Metric)**

* **指標:** **Mean Average Precision (mAP)** - 平均適合率の平均
* **計算方法:**
    1.  まず、各オブジェクトクラスごとにAverage Precision (AP) を計算します。APは、適合率-再現率曲線（Precision-Recall curve）の下部の面積として計算され、オブジェクトのクラス分類の正確さと位置特定（予測座標と正解座標の近さ）の精度を総合的に評価します。位置特定が「正しい」と判断されるためには、予測座標と正解座標の間の距離が、クラスごとに定められた特定の閾値（tolerance radius）以内である必要があります。
    2.  次に、全オブジェクトクラスについて計算されたAPを平均して、最終的なmAPスコアを算出します。
* **意味:** mAPは、オブジェクト検出タスクにおける標準的な評価指標です。複数のオブジェクトクラスが存在する場合に、モデルが全体としてどれだけ高い精度でオブジェクトを検出し、位置を特定できているかを示します。スコアは通常0から1の範囲となり、高いほど性能が良いことを意味します。特定の距離閾値を用いることで、単なるクラス分類だけでなく、空間的な位置精度も評価に組み込まれます。

要約すると、このコンペは、ノイズの多いCryoETの3D画像から複数の種類の分子オブジェクトを検出し、その3次元位置を特定するタスクです。データは3Dトモグラムと座標アノテーションで構成され、性能はクラス分類と位置特定の精度を総合的に評価するmAP（平均適合率の平均、特定の距離閾値に基づく）によって測られます。

---

**全体的な傾向:**

このコンペでは、3Dボリュームデータからの物体検出が課題であり、セグメンテーションベースの手法とヒートマップベースの手法が上位で採用されています。3D U-Netを基本としたアーキテクチャが多く見られ、データ拡張やアンサンブルも重要なテクニックとして活用されています。外部データ（シミュレーションデータ）の利用も一部で見られます。

**各解法の詳細:**

**1位**

- **アプローチ:** セグメンテーション（一部U-Net）と物体検出モデルのアンサンブル。外部データやシミュレーションデータは不使用。
- **アーキテクチャ:** MONAIのFlexibleUnet（エンコーダ: ResNet, EfficientNet-B3）、SegResNet、DynUnet。
- **アルゴリズム:** 3D U-Net、ResNet、EfficientNet、SegResNet、DynUnet。
- **テクニック:**
    - 7分割の実験IDに基づくクロスバリデーション。
    - 各エポック終了時に検証実験でクラス閾値をグリッドサーチで最適化。OOF予測で閾値を再調整。
    - 3D画像の標準化。
    - RandomCrop, Flip (各軸), Rotationによるデータ拡張。MixUpの独自実装。
    - 最終層の一つ前の特徴マップを使用する「一部U-Net」。
    - 背景クラスの重みを低く設定し、単一ピクセルをターゲットとする。
    - 重み付きCrossEntropy損失（beta-amylaseクラスも保持）。陽性ピクセルに高い重み。
    - コサイン学習率スケジューラ、混合精度学習。
    - 推論時のパッチ分割。
    - セグメンテーションモデルと物体検出モデルの予測を、ランクに基づいてスケーリングしてブレンド。
    - モデルのJITまたはTensorRTによるエクスポートによる推論高速化。

**2位**

- **アプローチ:** 軽量なセグメンテーションモデルのアンサンブル。セグメンテーション後、CC3Dで粒子中心を計算し、小さなクラスタをフィルタリング。
- **アーキテクチャ:** UNet3D, VoxResNet, VoxHRNet, SegResNet, DynUNet, DenseVNet, UNet2E3D。MONAI UNetをベースに正規化と活性化関数を調整。
- **アルゴリズム:** UNet3D、VoxResNet、VoxHRNet、SegResNet、DynUNet、DenseVNet。
- **テクニック:**
    - 公開LBスコアに基づいてモデルを選択。
    - 粒子タイプごとにカスタマイズされた半径のセグメンテーションマスク。
    - LionモデルとLuoziqianモデルで異なる学習設定（パッチサイズ、エポック数、オプティマイザ、損失関数、データ拡張）。
    - Lionモデル: AdamW, Tversky Loss, 重み付きCross-Entropy Loss, RandCropByLabelClassesdなど。
    - Luoziqianモデル: Early stopping, Dice Loss, Tversky Loss, スケールされたCross-Entropy Loss, RandCropByLabelClassesdなど。
    - 7種類のテスト時拡張 (TTA)。
    - 平均アンサンブル（重み付きも試行）。
    - 閾値ベースのクラスタリング（閾値0.15）。
    - クラスタサイズのフィルタリング。

**3位**

- **アプローチ:** 3D U-Netベースのセグメンテーションとcc3dによる後処理。Cross Entropy損失を使用。
- **アーキテクチャ:** Unet + ResNet101（segmentation_models_pytorch_3dを使用）。
- **アルゴリズム:** 3D U-Net、ResNet101。
- **テクニック:**
    - 4分割（7KF）の平均アンサンブル。
    - EMA（指数移動平均）。
    - 学習時の入力サイズ (64, 128, 128)、推論時の入力サイズ (64, 256, 256)。
    - 学習時のマスク半径を半分に。
    - フリップ (x, y, z軸)、軸の入れ替え (xとy)、異なるアルゴリズム（denoised, wbp, ctfdeconvolved, isonetcorrected）、simple copy past、mixupによるデータ拡張。
    - フリップ (x, y, z軸)、rot90 (x, y軸) による2種類のTTA。

**4位**

- **アプローチ:** ヒートマップベースの粒子点検出。2種類のUNetライクなモデル（2.5D-UNet）を使用。CVとLBの相関がない問題に対処するため、LBを重視。
- **アーキテクチャ:** yu4u's model (2.5D-UNet, ConvNeXt Nanoバックボーン), tattaka's model (軽量2.5D UNet, ResNetRS-50バックボーン)。
- **アルゴリズム:** UNet、ConvNeXt、ResNetRS。
- **テクニック:**
    - 粒子座標からガウス関数を用いてground truthヒートマップを作成（オフセット1.0を追加）。
    - yu4u's model: 2Dバックボーンの各ステージ出力を深度方向にプーリング、エンコーダとデコーダ間に3D畳み込み、ピクセルシャッフルによる最終ヒートマップ出力。
    - tattaka's model: 入力サイズ (32, 128, 128), Joint Pyramid Upsampling (JPU) をデコーダで使用。
    - MSEベースの損失関数（陽性・陰性サンプルをバランス）。
    - 4つのyu4u'sモデルと3つのtattaka'sモデルのアンサンブル。
    - TensorRT形式に変換して推論を高速化。
    - 非最大抑制 (NMS) によるローカル最大値検出。粒子タイプごとに異なる閾値でフィルタリング。
    - ピクセル座標から粒子座標への変換（オフセット補正、スケーリング）。

**5位**

- **アプローチ:** DeepFinderに触発されたネットワークアーキテクチャを用いたシンプルな粒子検出。
- **アーキテクチャ:** BatchNorm3dを入力層に追加、チャンネル数を削減した軽量なネットワーク（1.44MB）。最終アップサンプリングに転置畳み込みを使用。
- **アルゴリズム:** 3D CNN。
- **テクニック:**
    - 7つのボリュームデータセットの(5, 99)パーセンタイルを平均化してMin-Maxスケーリング。
    - ラベルを log2(radius) * 0.8 の半径の球として作成。
    - バッチサイズ4、パッチサイズ128x128x128で学習。
    - フリップ (全軸)、回転 (z軸)、平均と標準偏差のシフトによるデータ拡張。
    - Adamオプティマイザ、ラベルスムージングCross-Entropy損失。
    - float16精度での学習、勾配クリッピング。
    - 4つの異なるシードで学習したモデルのアンサンブル。
    - 推論時のパッチ分割（z軸方向は最小限のオーバーラップ、x/y軸方向はオーバーラップ+1）。
    - 3フリップと3回転によるTTA。
    - 接続成分分析によるバイナリマスクの後処理、面積の小さい成分を除去。

**6位**

- **アプローチ:** MONAIのsliding_window_inferenceを用いた推論と、複数のモデルの平均アンサンブル。
- **アーキテクチャ:** 2.5D UNet (エンコーダ: EfficientNet-B2, EfficientNetV2-B2, ConvNeXt-Nano, ResNet34d), MONAIの3D UNet, SegResNet。
- **アルゴリズム:** UNet、EfficientNet、ConvNeXt、ResNet、SegResNet。
- **テクニック:**
    - 10個の異なるモデルで推論を行い、予測マップを平均化。
    - 粒子タイプ固有の閾値で平均化されたマップを二値化。
    - 接続成分分析で粒子位置（重心）を計算。
    - 外れ値除去、Min-Max正規化。入力ボリュームを64x128x128にクロップ。
    - 粒子中心のバイナリマスクをラベルとして使用（半径*0.5以内を1）。
    - FocalTversky++損失を使用。
    - polnetで生成したシミュレーションデータで一部モデルを事前学習。
    - 推論時にsliding_window_inference（オーバーラップ0.25）、エッジ付近の予測を破棄。
    - TensorRTに変換して推論を高速化。
    - クロスバリデーションとLBに基づいて粒子固有の閾値を調整。

**7位**

- **アプローチ:** クラスごとのガウスヒートマップ予測を行う3Dセグメンテーションモデル。シミュレーションデータでの事前学習と実験データでのファインチューニング。
- **アーキテクチャ:** U-Net (バックボーン: ResNet50d, EfficientNetV2-M), DeepLab (バックボーン: ResNet50d)。
- **アルゴリズム:** U-Net、ResNet、EfficientNet、DeepLab。
- **テクニック:**
    - シミュレーションデータ全体で事前学習、実験データのwbpバージョンで検証。
    - パーセンタイルクリッピング、データセット固有のスケーリング。
    - スライディングウィンドウによるパッチ分割とランダムシフト。
    - シフト、CutMix、MixUp、RandomFlip、Affine（xy平面のみ）、Rot90（xy平面のみ）、ピクセル値拡張による強力なデータ拡張。
    - 重み付きBCE損失（陽性ピクセルに高い重み）。
    - コサイン学習率スケジューラ、AdamWオプティマイザ。
    - EMA（指数移動平均）。
    - 3つのモデルスープ（各4フォールド）のアンサンブル。
    - 4x TTA、4x スライディングウィンドウ推論。
    - ロジットを平均化してヒートマップを結合。
    - エッジアーティファクトを軽減するための傾斜付き重み関数。
    - ローカル最大値検出前にガウシアンブラー、検出後に重み付きボックス融合 (WBF)。
    - ロジット空間での閾値処理。
    - LBプロービングによるTP/FP/FNの推定。

**8位**

- **アプローチ:** 異なるモデルサイズ、パラメータ、学習データで学習された4つの3D U-Netモデルスープのアンサンブル。
- **アーキテクチャ:** MONAIの3D U-Net（異なるチャンネル数、ストライド、残差ユニット数）。
- **アルゴリズム:** 3D U-Net。
- **テクニック:**
    - パッチサイズ (128, 128, 128) で学習、(160, 384, 384) で25%オーバーラップのスライディングウィンドウ推論（ガウス再構成）。
    - フリップと転置による幾何学的TTA。
    - ガウシアンノイズでノイズ除去した合成データで事前学習。
    - MONAIのDiceCELoss、AdamWオプティマイザ、学習率低下。EMAも実験。
    - 7分割クロスバリデーション。
    - ロジットレベルでのモデル予測の結合。
    - 分水嶺セグメンテーションによる粒子の分離。
    - 粒子固有のブロブ閾値サイズ。

**9位**

- **アプローチ:** 3D ConvNeXtライクなモデルによるセグメンテーションと、可能な限り多くのモデルのアンサンブル。その後、cc3dで重心を計算し、DBSCANでクラスタリング。
- **アーキテクチャ:** カスタマイズされた3D ConvNeXtライクモデル（エンコーダ: 2D ConvNeXtを3D化、ステムと畳み込みブロックのカーネルサイズ変更、ブロック数削減、デコーダ: U-Netベース、基本的なUpsampleを使用）。
- **アルゴリズム:** ConvNeXt、U-Net、DBSCAN。
- **テクニック:**
    - 粒子タイプごとに調整された半径のground truthマスク。
    - エンコーダのカスタマイズ（2Dから3Dへの変換、ステムと畳み込みブロックの調整）。
    - デコーダに基本的なUpsampleを使用。
    - BCE損失。
    - 推論コードは Hengckのノートブックがベース、DBSCANのアイデアは linheshenのノートブックから。
    - 推論ウィンドウサイズ (32, 320, 320)、学習ウィンドウサイズ (32, 256, 256)。
    - TTAs are rot90, 180 and 270.
    - 正規化のみの前処理。
    - Rot90, 180, 270、XYZフリップによる学習時のデータ拡張。

**10位**

- **アプローチ:** 9つのヴィンテージ3D U-Netのアンサンブル。ほとんどがシミュレーションデータで事前学習後、コンペデータでファインチューニング。
- **アーキテクチャ:** MONAIのUNet (spatial_dims=3, channels=(48, 64, 80, 80, 128), stride_patterns=(2,2,2,1))。
- **アルゴリズム:** 3D U-Net。
- **テクニック:**
    - 実験IDに基づくtrain/validation分割。
    - MONAIのNormalizeIntensitydによる正規化。
    - MONAIのRandFlipd, RandRotated, RandRotate90dによるデータ拡張。MixUpも使用（alphaは小さい）。
    - Optunaによるハイパーパラメータ探索。PyTorch Lightningで学習。
    - AdamWオプティマイザ、コサイン学習率スケジューラ。
    - ファインチューニングの損失関数: Tversky損失とマルチクラスCrossEntropy損失の重み付き組み合わせ。
    - シミュレーションデータでの事前学習には、ファインチューニングと同じ損失、粒子方向ベクトルを目的とした損失、バグありの方向ベクトル損失の3種類を使用。
    - KLダイバージェンス最小化に基づく後処理による重複検出の分割。
    - 境界線と重心を用いた追加の後処理。