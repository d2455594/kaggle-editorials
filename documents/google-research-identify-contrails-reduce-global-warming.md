---
tags:
  - Kaggle
startdate: 2023-05-11
enddate: 2023-08-10
---
# Google Research - Identify Contrails to Reduce Global Warming
https://www.kaggle.com/competitions/google-research-identify-contrails-reduce-global-warming

**概要 (Overview)**

- **目的:** このコンペティションの目的は、**衛星画像データ**を使用して、航空機によって生成される**飛行機雲（Contrails）を特定・検出する**機械学習モデルを開発することです。
- **背景:** 飛行機雲は、特定の条件下で持続し、巻雲（Cirrus clouds）のような雲に変化することがあります（Contrail-Cirrus）。これらの雲は地球の熱を宇宙に逃がさず、地表を温める効果（放射強制力）を持ち、航空機によるCO2排出以上に地球温暖化に寄与している可能性が指摘されています。飛行機雲を正確に特定できれば、それらが発生・持続しやすい空域を避けるように飛行経路をわずかに調整するなど、気候への影響を軽減する戦略の実現につながる可能性があります。このコンペティションは、Google Researchが気候変動対策の一環として支援しています。
- **課題:** 飛行機雲は、自然に発生する巻雲と見た目が非常に似ているため、衛星画像から自動で区別することは困難です。また、飛行機雲の形状や特性は時間とともに変化し、大気条件にも依存します。データは複数の波長帯（特に赤外線）を含む衛星画像であり、時間的な連続性も考慮する必要があるため、複雑な時空間パターンを捉える能力がモデルに求められます。これは、マルチスペクトル・時系列衛星画像に対する**セマンティックセグメンテーション（領域分割）タスク**です。

**データセットの形式 (Dataset Format)**

提供される主なデータは、特定の地域と期間をカバーする連続した衛星画像シーケンスと、それに対応する飛行機雲の正解マスク（ラベル）です。

1. **トレーニングデータ:**
    
    - 各データは `record_id` によって識別される、一連の時系列衛星画像データです。
    - 各レコードには、複数の時間ステップにおける衛星画像フレームが含まれます。画像は複数の**波長帯（バンド）**の情報を含んでおり（例: GOES衛星の赤外バンドなど）、通常 NetCDF や NumPy 配列などの形式で提供されます。(`train/{record_id}/`)
    - `contrails.csv`: **ターゲット変数**となる飛行機雲の正解マスクが含まれます。このファイルには `record_id` と、対応する画像フレーム内の飛行機雲のピクセル位置を示す**ランレングスエンコーディング (RLE)** 形式の文字列 (`encoded_pixels`) が格納されています。
    - `human_pixel_masks.npy` のようなファイルで、人間がラベル付けした領域を示すマスクが提供される場合もあります。
2. **テストデータ:**
    
    - トレーニングデータと同様の形式で、複数のレコードのマルチバンド衛星画像シーケンスが提供されます (`test/{record_id}/`)。
    - 飛行機雲の正解マスクは提供されません。参加者はこれらのテストデータに対して飛行機雲の領域を予測します。
3. **`sample_submission.csv`**:
    
    - 提出フォーマットのサンプル。通常、`record_id` と `encoded_pixels` の列を持ちます。`encoded_pixels` 列には、各 `record_id` に対応する**予測された飛行機雲マスク全体のランレングスエンコーディング (RLE) 文字列**を格納します。飛行機雲が検出されなかった場合は空文字列を提出します。

**評価指標 (Evaluation Metric)**

- **指標:** **Global Dice Coefficient (グローバルダイス係数)**
- **計算方法:** ダイス係数は、予測された領域と正解領域の重複度を測る指標で、セグメンテーションタスクで一般的に用いられます。以下のように計算されます（F1スコアと同等です）。
    - Dice = (2 * |予測領域 ∩ 正解領域|) / (|予測領域| + |正解領域|)
    - ここで、`|予測領域 ∩ 正解領域|` は正しく飛行機雲と予測されたピクセル数（True Positives）、`|予測領域|` は飛行機雲と予測された全ピクセル数、`|正解領域|` は実際に飛行機雲である全ピクセル数です。
    - **Global** Dice は、個々の画像やレコードごとにDice係数を計算して平均するのではなく、**テストデータセット全体のピクセル**をまとめて分子・分母を計算します。これにより、飛行機雲の領域が非常に小さい場合にスコアが不安定になるのを防ぎます。
- **意味:** モデルが予測した飛行機雲のピクセルが、実際の飛行機雲のピクセルとどれだけ一致しているかを示します。値は0から1の範囲を取り、1に近いほど予測精度が高いことを意味します。Global Dice Coefficient が**高い**ほど、テストデータセット全体で飛行機雲の形状と位置をより正確に捉えられていると評価されます。

要約すると、このコンペティションは、地球温暖化への影響を軽減する目的で、時系列衛星画像から飛行機雲を検出するセマンティックセグメンテーションタスクです。データはマルチバンドの画像シーケンスとRLE形式の正解マスクで構成され、性能は予測と正解の重複度を全体で評価する Global Dice Coefficient（高いほど良い）によって測られます。

---

**全体的な傾向**

このコンペティションでは、衛星画像から飛行機雲（Contrails）の領域を特定するセグメンテーションタスクが求められました。上位解法の多くは、U-Netベースのアーキテクチャを採用し、エンコーダーにはTransformer系（MaxViT, CoAt, SAM-Bなど）やCNN系（EfficientNet, ResNe(X)tなど）の多様なバックボーンが使用されました。時間変化を捉えるため、複数フレームを入力とする2.5Dアプローチや、中間層で時間方向の畳み込み（3D Conv）や系列モデル（LSTM）を組み込む手法も有効でした。

データセット特有の課題として、アノテーションのノイズ（複数アノテーター間の不一致）と、マスクラベルの0.5ピクセルずれが存在しました。これらに対処するため、複数アノテーションの平均値をターゲットとするソフトラベルの利用や、ピクセルずれを補正するための入力画像シフト、あるいは対称化されたラベルでの学習といったテクニックが重要な鍵となりました。特に、ラベルずれを考慮せずに回転や反転などの幾何学的Augmentationを行うと性能が低下するため、ずれを補正した上でのAugmentation適用や、TTA（Test Time Augmentation）が効果を発揮しました。高解像度の入力画像の使用や、疑似ラベルによる学習データ拡張も試みられましたが、疑似ラベルの効果は限定的とする意見もありました。損失関数としては、Binary Cross Entropy (BCE) と Dice Loss（またはその派生形であるLovasz Lossなど）の組み合わせが一般的でした。最終的な精度向上には、複数モデルのアンサンブルが不可欠でした。

**各解法の詳細**

**1位**

- **アプローチ:** U-Net+MaxViTモデルを使用。ラベルの0.5ピクセルずれを発見し、対称化ラベル(y_sym)で学習後、小さなCNNで最終的なずれを補正する独自の手法を開発。
- **アーキテクチャ:** U-Net + MaxViT_tiny_tf_512 Encoder。ずれ補正用の小さなConv5x5ネットワーク。
- **アルゴリズム:** BCE損失。AdamW。Cosine Annealing w/ Warmup。8-TTA (rot90, flip)。
- **テクニック:**
    - **ラベル処理:** アノテーション平均値をソフトターゲットとして使用。0.5ピクセルシフトした対称化ラベル(y_sym)を生成しU-Netで学習。学習済みU-Netの特徴量から、小さなCNNで元の右下ズレのターゲット(y)へのマッピングを学習。
    - **入力:** 標準的なash color画像。高解像度入力(1024x1024)。
    - **モデル:** 単一時刻(t=4)入力モデルと、4時刻(t=1-4)をパネル状に結合した入力モデルの2種類を学習。後者はMaxViTのSelf-Attentionで時間情報を捉えることを期待。
    - **Augmentation:** RandomRotate90, HorizontalFlip, ShiftScaleRotate。ラベルずれ補正により効果を発揮。
    - **アンサンブル:** 単一時刻モデルと4時刻パネルモデルの重み付き平均。閾値はValidationで最適化。

**2位**

- **アプローチ:** ピクセルレベルの精度向上に注力。高解像度入力とカスタムU-Net系アーキテクチャを採用。時間情報を中間特徴量レベルで混合。
- **アーキテクチャ:** カスタムU-Net形状 (Encoder + Decoder)。Encoder: CoaT, NeXtViT, SAM-B, tf_efficientnetv2_s。Decoder: U-block (Pixel Shuffle Upsampling, Factorized FPN)。時間混合モジュール: LSTM, Transformer, 1D Conv。
- **アルゴリズム:** BCE + Dice Lovasz損失。Over9000 (Radam+LAMB+LookAhead) または AdamW。
- **テクニック:**
    - **高解像度化:** 入力画像をx2またはx4にアップサンプリング。DecoderでのアップサンプリングにPixel Shuffleや転置畳み込みを使用。
    - **ラベル処理:** ソフトラベル（アノテーション平均値）を使用。
    - **時間情報混合:** 中間解像度(res/32, res/16)の特徴マップに対してLSTM、Transformer、または1D Convを適用し時間情報を混合。
    - **疑似ラベル:** 外部データ(Contrails GOES16 Images May)で疑似ラベル学習（モデルの多様性低下のため、最終的なアンサンブル性能への寄与は限定的）。
    - **Augmentation:** ShiftRotateScale, RandomGamma, RandomBrightnessContrast, MotionBlur, GaussianBlurなど。ラベルずれのためFlip/90度回転は不使用。
    - **その他:** DecoderのBatchNormをLayerNorm2dに置換。GELU活性化関数。
    - **アンサンブル:** 8つのモデル（異なるアーキテクチャ、時間混合方式、疑似ラベル有無）を重み付き平均。

**3位**

- **アプローチ:** U-Netの中間層に3D畳み込みを導入した2.5Dアーキテクチャ。ソフトラベルと疑似ラベルを活用。
- **アーキテクチャ:** 2.5D U-Net (smp.Unetベース)。Encoder: MaxViT_large/base, tf_efficientnet_l2/v2_xl, ResNeSt269eなど多様。DecoderのSkip Connectionに3D Conv Blockを挿入。
- **アルゴリズム:** (Dice + BCE) / 2 損失。AdamW。Cosine Annealing w/ warmup。パーセンタイル閾値。
- **テクニック:**
    - **2.5D構造:** U-Netの各解像度の特徴マップ（Skip Connection前）に対し、時間方向にカーネルサイズ2の3D Convを2回適用し、フレーム次元を集約。
    - **ラベル処理:** ソフトラベル（アノテーション平均値）を使用。
    - **疑似ラベル:** 未ラベルフレーム（t=2,3,5,6,7）に対し、学習済みモデルの予測値を0.25で離散化し疑似ラベルとして使用（事前学習→ファインチューニング）。
    - **Augmentation:** Flip, Rotate90を低確率(p=0.1-0.4)で適用。ShiftScaleRotate, RandomResizedCrop。
    - **閾値決定:** Validationデータでの最適閾値のパーセンタイル（約0.16%）をテストデータに適用。
    - **その他:** Grad_checkpointingでメモリ削減。U-Netデコーダチャネル数増加。Dice損失計算の安定化策。
    - **アンサンブル:** 18の2.5Dモデル（異なるバックボーン、疑似ラベル有無、Validationデータ学習有無など）＋チームメンバーのモデルをアンサンブル（重み付けは不明）。

**4位**

- **アプローチ:** U-Net + 多様なEncoder。疑似ラベル生成によるデータ拡張。EMA+SWAによる学習安定化。高解像度入力とTTA。
- **アーキテクチャ:** U-Net。Encoder: effnet_v2_l, effnet_v2_xl, effnet_l2, maxvit。
- **アルゴリズム:** CE + Dice + Focal損失（重み付け）。EMA (Exponential Moving Average)。SWA (Stochastic Weight Averaging)。4-TTA (hflip, rot90, rot270)。
- **テクニック:**
    - **疑似ラベル:** 3モデルx4Foldで2ラウンドかけて全データにソフト疑似ラベルを生成。訓練時は元データ50%、疑似ラベル50%の割合でサンプリング。
    - **学習:** 高解像度入力(512, 768)。EMAとSWAを併用。
    - **Augmentation:** 垂直Flipは不使用。4TTAは学習時のValidationでも適用。
    - **その他:** U-NetデコーダーからBatchNormを除去。
    - **アンサンブル:** 異なる解像度(512, 768)のモデルを含むアンサンブル。

**5位**

- **アプローチ:** 単一フレームモデルとマルチフレーム(3D)モデルの組み合わせ。ラベルのピクセルずれを補正した上での幾何学AugmentationとTTA。
- **アーキテクチャ:** 2D: EfficientNetV2L + UNet。3D: EfficientNetV2L + カスタム3D UNet (各フレームEncoder出力にConv3D/ConvLSTM2D適用後、UNet Decoderへ)。
- **アルゴリズム:** 重み付き BCE + Dice損失。Lionオプティマイザ。8-TTA (flip LR/UD, rot90)。
- **テクニック:**
    - **ラベルずれ補正:** 画像とマスクのずれ(x=0.408, y=0.453ピクセル)を特定し、学習/推論時に補正。これによりFlip/Rotate AugmentationとTTAが有効に。
    - **入力:** 高解像度入力(512, 768)。入力クロップ。
    - **ターゲット:** 2種類（①1chソフトラベル、②5ch個別アノテーション数カテゴリ）。両者を重み付けして使用。
    - **マルチフレーム:** 5フレームまたは8フレーム入力。
    - **Augmentation:** Flip LR/UD, Rotate90, Channel/Pixel Noise, Random Dropout Frame (Multi-frame)。
    - **アンサンブル:** 5モデル（2D x2, 3D x3）のTTA8結果をアンサンブル（重み付け不明）。

**6位**

- **アプローチ:** 2段階パイプライン（分類→セグメンテーション）。2.5Dモデルと、全11chを入力とする2Dモデルをアンサンブル。ソフトラベル使用。
- **アーキテクチャ:** 分類: 2.5D (ResNetRS101など + 3D CNN)。セグメンテーション (pos only): 2.5D (ResNetRS101など + 3D CNN + UNet)。セグメンテーション (all data): 2D U-Net (Res2Net50d, RegNetZなど)。
- **アルゴリズム:** BCE損失、Dice損失。パーセンタイル閾値。EMA。
- **テクニック:**
    - **パイプライン:** 先に分類モデルでContrail有無を判定し、陽性の場合のみセグメンテーションモデルの予測を使用。
    - **2.5Dモデル:** Vesuviusコンペ解法ベース。複数フレーム(5 or 7)入力。特徴マップに3D CNN適用。
    - **2Dモデル:** 全9バンド+差分2バンドの計11chを入力。False Color入力より長期学習で高精度に。
    - **ラベル処理:** ソフトラベル（アノテーション平均値）を使用。
    - **学習:** pos_onlyモデルとall_dataモデルを別途学習。Augmentationはモデル種別で変更。EMA使用。
    - **閾値決定:** 分類・セグメンテーション共にValidationデータで最適化したパーセンタイル閾値を使用。
    - **アンサンブル:** 2.5Dモデルと2Dモデルを含む複数モデルのアンサンブル（重み付け不明）。

**7位**

- **アプローチ:** U-Net+EfficientNetモデル。非バイナリターゲット（ソフトラベル）。直交化9チャンネル入力による色空間変換。
- **アーキテクチャ:** U-Net + EfficientNet Encoder (b7, b8)。
- **アルゴリズム:** BCE損失主体（Dice少量追加）。AdamW。Cosine Annealing w/ warmup。8-TTA (推定)。
- **テクニック:**
    - **入力:** 高解像度入力(512x512)。
    - **色空間:** 元の9チャンネル(band 8-16)をSVDで直交化し、標準偏差でスケーリングしたものを入力として使用（ASH-RGBより高性能）。
    - **ラベル処理:** ソフトラベル（アノテーション平均値）を使用。
    - **Augmentation:** Rotate90, Flip, ShiftScaleRotate。
    - **学習:** bf16混合精度。
    - **アンサンブル:** 異なる損失関数やEncoderを持つ5つのモデルを重み付き平均（Logits空間で計算）。閾値はValidationで最適化。

**8位**

- **アプローチ:** OneFormer (DINAT-L) を中心とした多様なモデルのアンサンブル。ソフトラベルと疑似ラベルの併用。Optunaによるアンサンブル重み最適化。
- **アーキテクチャ:** OneFormer (DINAT-L)。その他: EfficientNet (b7, b8), MaxViT (Tiny, Base), ResNetRS, NFNetF5。
- **アルゴリズム:** BCE損失。Optuna (アンサンブル重み最適化)。
- **テクニック:**
    - **モデル:** OneFormerが最高性能。多様なバックボーンを試行。
    - **ラベル処理:** ソフトラベル（アノテーション平均値）を使用。疑似ラベルも併用（t=4のみソフトラベル、他は疑似ラベル）。
    - **学習:** モデルごとに異なる解像度(512-1024)。
    - **アンサンブル:** Optunaを用いてValidationスコアに基づきモデルの重みを最適化。

**9位**

- **アプローチ:** ラベルの0.5ピクセルずれを発見し、入力画像をシフトさせることで補正。これにより通常のAugmentation/TTAを可能にする。
- **アーキテクチャ:** U-Net。EncoderはEfficientNetなど (詳細不明)。
- **アルゴリズム:** アフィン変換による画像シフト。
- **テクニック:**
    - **ラベルずれ補正:** 学習・推論時に`cv2.warpAffine`を用いて入力画像を+0.5ピクセルシフトし、マスクとの位置ずれを解消。
    - **モデル:** U-Net。強力なバックボーンが有効。
    - **ラベル処理:** 個々のアノテーション全体で学習することが有効。
    - **その他:** 疑似ラベルも試したが時間切れ。他バンド利用、2.5Dアプローチは断念。


