---
tags:
  - Kaggle
  - NLP
startdate: 2024-04-25
enddate: 2024-07-25
---
# USPTO - Explainable AI for Patent Professionals
https://www.kaggle.com/competitions/uspto-explainable-ai

**概要 (Overview)**

* **目的:** このコンペティションの目的は、特許文献中のフレーズ（専門用語や概念）間の意味的な類似性や関連性を自動的に判断し、さらにその判断の**根拠を「説明」できるAIモデル**を開発することです。具体的には、ある「アンカー」フレーズと「ターゲット」フレーズが、特定の特許分類（例: CPC - 協同特許分類）の文脈において、どの程度同じ意味を持つかをスコアで予測することが求められます。「説明可能AI（Explainable AI - XAI）」がタイトルに含まれている通り、単に予測するだけでなく、その予測に至った理由（例: 関連する特許文献中の根拠箇所）を提示する能力も、コンペティションの重要な側面である可能性があります。
* **背景:** 米国特許商標庁（USPTO）では、特許審査官が新規出願を既存の特許（先行技術）と比較し、新規性や進歩性を判断します。これには、異なる文献間で技術用語の意味を正確に理解する必要があります。AIは意味的に類似した概念を見つけることで審査官を支援できますが、審査官がその結果を信頼し活用するためには、AIが「なぜ」それらを類似と判断したのか（説明可能性）を理解できることが重要です。
* **課題:** 特許文献特有の専門的で難解な言語を理解すること。文脈によって意味が変わるフレーズ間の微妙な意味的同等性を捉えること。そして、予測の根拠となる適切な説明（例: 文献中の関連箇所）を生成または特定すること。タスクは、**意味類似性スコアの予測（回帰または順序分類）**と、**説明（根拠）の提示**という複数の要素を含む可能性があります。

**データセットの形式 (Dataset Format)**

提供される主なデータは、特許文献から抽出されたフレーズペアと、それらの関連情報です。

1.  **メインデータ (`train.csv`, `test.csv` など):**
    * 通常、CSV形式で提供され、各行が評価対象のフレーズペアに対応します。
    * 列には通常、以下が含まれます。
        * `id`: ペアの識別子。
        * `anchor`: 基準となるフレーズ。
        * `target`: 比較対象となるフレーズ。
        * `context`: フレーズが属する文脈を示す情報（例: CPC分類コード）。
        * `score`: **ターゲット変数**。アンカーとターゲットの意味的類似度を示すスコア（例: 0, 0.25, 0.5, 0.75, 1 のような段階的な値）。
    * トレーニングデータ (`train.csv`) には `score` が含まれますが、テストデータ (`test.csv`) には含まれません。

2.  **特許分類コードデータ (`cpc_codes.csv`, `titles.csv` など):**
    * `context` として使用されるCPCコードの階層構造やタイトル（説明）などの情報を提供するファイル。

3.  **(オプション) 特許文献テキストデータ:**
    * フレーズが現れる元の特許文献の全文テキストデータ。これは、特に「説明」部分（根拠箇所の特定）がタスクに含まれる場合に必要となります。大規模なテキストコーパスとして提供される可能性があります。

4.  **(オプション) 説明データ:**
    * トレーニングデータにおいて、特定の `score` の根拠となる特許文献中のテキストスパン（箇所）がアノテーションされている場合があります。

5.  **`sample_submission.csv`**:
    * 提出フォーマットのサンプル。通常、`id` と、予測された `score` の列を持ちます。説明部分の提出形式が別途定義される可能性もあります。

**評価指標 (Evaluation Metric)**

* **指標:** **Pearson Correlation Coefficient (ピアソンの積率相関係数)**
* **計算方法:** 予測された類似性スコアのベクトルと、実際の（人間が付与した）類似性スコアのベクトルとの間の線形相関の強さを測定します。値は -1 から 1 の範囲を取ります。
    ρ = Cov(予測スコア, 実際スコア) / (StdDev(予測スコア) * StdDev(実際スコア))
* **意味:** ピアソン相関係数は、モデルの予測スコアが実際のスコアとどれだけ直線的な関係にあるかを示します。値が**1に近い**ほど、モデルが実際のスコアの傾向（大小関係）を正確に捉え、相対的な類似度をうまく予測できていることを意味します。これは、段階的な類似性スコアを予測するタスクの評価に適しています。
* **注意点:** コンペティションの主眼である「説明可能性」の部分がどのように評価されるかは、別途定義される可能性があります（例: 根拠スパン特定タスクであればF1スコアなど）。しかし、主要なランキング指標としては、類似性スコア予測に対するピアソン相関係数が用いられる可能性が高いです（過去の類似USPTOコンペでの実績より）。

要約すると、USPTOコンペティションは、特許文献中のフレーズ間の意味的類似度を、特定の文脈（CPCコード）を考慮してスコアで予測するタスクであり、「説明可能性」も重要な要素です。データはフレーズペア、文脈コード、類似度スコア（CSV）で構成され、特許本文データも関連する可能性があります。主要な性能評価は、予測スコアと実際のスコアとの間のピアソン相関係数（高いほど良い）によって行われます。

---

**全体的な傾向:**

このコンペでは、特許データに基づいて、与えられたターゲット特許と関連性の高い特許を検索するためのWhooshクエリを作成することが課題でした。上位解法は、主にキーワードベースの検索戦略と、クエリの最適化に重点を置いています。特に、ANDとOR演算子を効率的に使用し、トークン数を削減するテクニック、そして、ターゲット特許にのみ関連するキーワードを選択することが重要でした。また、一部の解法では、コンペティションの評価指標やデータ特性に関する深い洞察に基づいた「魔法」のようなテクニックも用いられています。

**各解法の詳細:**

**1位**

- **アプローチ:** シミュレーテッドアニーリング（SA）を用いて、ORで結合されたサブクエリの最適な組み合わせを探索。サブクエリは、ターゲット特許にのみ含まれるキーワード（AND結合）で構成。
- **アーキテクチャ:** Whoosh検索エンジン。
- **アルゴリズム:** シミュレーテッドアニーリング（SA）、カップイー（高速な共通集合計算）。
- **テクニック:**
    - **クエリ構築:** ANDとORのみを使用。'-' でANDを省略。CPCコードを最後に配置。タイトル、要約、クレーム、説明の全ての単語を使用（クレームと説明は高頻度語を削除）。
    - **候補生成:** 単一ターゲットまたは2つのターゲットに共通する単語セットから、ターゲット特許のみを含むサブクエリを生成。単語を要素数でソートし、要素数の昇順に単語を追加。
    - **高速化:** 要素数の昇順に単語を追加、カップイーによる共通集合計算の高速化、メモリ使用量の削減（テストデータと関連単語のみ保持）。
    - **シミュレーテッドアニーリング:** サブクエリの追加・削除を近傍探索とするSA。スコア関数はクエリの検索結果に含まれるターゲット数。重複サブクエリの削除。

**2位**

- **アプローチ:** ターゲット特許のみを含むクエリの構築。魔法（空白なしAND、空白なしn-gram）を利用した高スコア解と、魔法なしの解を開発。
- **アーキテクチャ:** Whoosh検索エンジン、カスタム高速検索アルゴリズム（C++実装）。
- **アルゴリズム:** TF-IDF（順位付け）。ビームサーチ（クエリ生成）。
- **テクニック:**
    - **魔法:** 空白なしAND (`ti:"abcd"ab:"efgh"clm:"ijkl"`)、空白なしn-gram (`ti:"abcd/efgh/ijkl"`)。
    - **指標とテストデータ:** テストインデックスには意図的に非ターゲットに類似した非ターゲットが含まれている可能性。非ターゲットを含まないクエリの重要性。
    - **検証:** 1975年以降のランダムな特許データを使用。非ターゲットを含まないクエリに限定。
    - **ソリューション:** (サブクエリ OR ...) NOT (否定サブクエリ OR ...)。サブクエリと否定サブクエリはAND結合された複数の単語。インデックス構築（C++）、サブクエリ候補生成、クエリで使用するサブクエリの選択（貪欲法、ビームサーチ）。高頻度語の削除（クレーム、説明）。

**3位**

- **アプローチ:** 平均プロンプトとモデルの予測のハイブリッド。敵対的攻撃と、モデルの特性を利用したスコア操作。
- **アーキテクチャ:** Mistral 7B。
- **アルゴリズム:** ビームサーチ、LBFGS（平均プロンプト最適化）、KMeans、HDBSCAN。
- **テクニック:**
    - **敵対的攻撃:** 特定の単語リストと、モデルの特性に合わせた指示（例: 特定のモデル名に言及する、特定の単語の繰り返し、他の言語の利用）。
    - **平均プロンプト:** 候補プロンプトデータセットから、LBの分布に合わせたサブサンプルを選択し、ビームサーチで最適化。
    - **フルプロンプト予測モデル:** LoRAファインチューニングされた `mistralai/Mistral-7B-Instruct-v0.2`。
    - **ゲートモデル:** 誤ったプロンプト予測をフィルタリングするための二値分類モデル（Mistral）。
    - **タグ予測モデル:** サンプルのタグ（例: "shanty", "summarize"）を予測するモデル（Mistral）。
    - **クラスタリング:** テストサンプルをクラスタリングし、最適な平均プロンプトテンプレートを選択。

**4位**

- **アプローチ:** 魔法（空白なしAND）を利用したクエリ構築。ターゲット特許をペアに分割し、共通トークンをAND結合。ORで結合。非ターゲットを除外。
- **テクニック:**
    - **魔法:** 空白なしAND (`"token1"ti:"token2"...detd:"token25"`)。
    - **ペアマッチング:** ターゲット特許を25ペアに分割し、出現頻度の高い順に最大25個の共通トークンをAND結合。
    - **クエリ構築:** ペアのクエリをOR結合。
    - **非ターゲットの除去:** クエリ実行後に非ターゲットがヒットした場合、そのクエリは使用しない。
    - **個別ターゲットのヒット:** ペアでヒットしなかった未使用ターゲットを、追加トークンを用いて個別にヒットさせる。
    - **トークン数の削減:** 共通トークンを可能な限り追加。

**5位**

- **アプローチ:** 最小限の偽陽性で多くの真陽性を集める。グローバルカウンター候補と50c2候補。ソルバーで最大25個の候補を選択し、ORで連結。トークン数の削減（特殊AND）。
- **アーキテクチャ:** Whoosh検索エンジン。
- **アルゴリズム:** 整数線形計画法（ILP）（候補の最適選択）、IDF（逆文書頻度）。
- **テクニック:**
    - **グローバルカウンター候補:** 全特許における単語/n-gramの出現回数をカウント。近傍特許における出現とグローバルカウンターの出現を比較して候補を生成（TPとFPを推定）。
    - **50c2候補:** 近傍特許から2つを選択し、共通単語をAND結合したクエリを生成。IDFを用いてFPがゼロと推定される候補のみ保持。
    - **トークン数の削減:** 特殊AND (`ti:"dog"ti:"cat"`) を使用してトークン数を削減。
    - **セットカバー問題:** ILPソルバーを用いて、TPを最大化しFPを最小化する候補の最適な組み合わせを選択（トークン数50以下）。

**6位**

- **アプローチ:** 段階的なサブクエリ探索とビームサーチによるクエリ生成。カスタム検索エンジン（C++）。
- **アーキテクチャ:** カスタム検索エンジン（C++）。
- **アルゴリズム:** ビームサーチ。
- **テクニック:**
    - **インデックス構築:** 全特許の単語から単語-特許、特許-単語の二次元可変長リストを作成（整数ID化）。高頻度語を削除（クレーム、説明）。
    - **サブクエリ候補生成:** 50個の単一ターゲットと50*49/2個のターゲットペアに対応するサブクエリ候補を作成。ベースワードセット（単一ターゲットは全単語、ペアは共通単語）。特許サイズの昇順ソートと非ターゲット除去による高速化。
    - **クエリ構築:** スコア関数（新規ターゲット数 - (ターゲット出現頻度 * 10^-9)）に基づく貪欲法とビームサーチ。

**7位**

- **アプローチ:** 「魔法」（偽のスペース文字）を利用したクエリ構築。
- **テクニック:**
    - **魔法:** `~` などの文字はWhooshでは空白として扱われるが、トークン数カウント関数では無視されるため、これを利用してクエリを短くする (`ti:"t1_1~t1_2~t1_3~..."`)。
    - **GPUによる高速化:** `cudf-pandas` を使用して処理を高速化。
    - **正確なタイトルクエリ:** 25個の正確なタイトルをクエリすることでLB 0.8以上を達成。

**10位**

- **アプローチ:** ターゲット特許に関連し、テスト内の他の特許に関連しない(cpc, ti, ab, detd)ペアを作成。トークン数を節約するためにペアをソートしてマージ。
- **テクニック:**
    - **ペア作成:** 各テスト行に関連するcpc、タイトルなどを計算し、ペアを生成。ペアが他のテスト特許に関連しない、またはテスト外の特許よりも関連性が低い場合に使用。
    - **トークン数の削減:** 同じトークンを持つペアをマージ。