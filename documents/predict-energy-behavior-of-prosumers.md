---
tags:
  - Kaggle
startdate: 2023-11-03
enddate: 2024-05-01
---
# Enefit - Predict Energy Behavior of Prosumers
[https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers)

**概要 (Overview)**

* **目的:** このコンペティションの目的は、エストニアのエネルギー市場におけるプロシューマー（太陽光発電設備を持つエネルギーの生産者兼消費者）の**エネルギー消費量と生産量を予測する**モデルを開発することです。具体的には、今後2日間の1時間ごとのエネルギー量を予測します。
* **背景:** Enefitはエストニアの大手エネルギー企業です。再生可能エネルギー、特に分散型太陽光発電の普及が進む中で、個々のプロシューマーの発電量と消費量を正確に予測することは、電力系統の安定運用、需給バランスの最適化、効率的なエネルギー取引のために不可欠となっています。
* **課題:**
    * **高精度な時系列予測:** 2日先までの詳細な（1時間ごとの）消費量・生産量を予測する必要があり、時間的な依存性やパターンを捉えることが重要です。
    * **多様な影響要因:** プロシューマーのエネルギー行動は、天候（特に日射量、気温、雲量）、電力価格、ガス価格、時間帯（時刻、曜日、季節）、顧客属性（家庭/ビジネス、契約タイプ、設置容量）、祝日など、多数の要因に複雑に影響されます。
    * **データ統合:** 過去の消費/生産量データ、顧客情報、気象予報データ、過去の気象データ、エネルギー価格データなど、複数の異なる情報源を効果的に統合する必要があります。
    * **予測対象の二面性:** 同じプロシューマーグループに対して、消費量と生産量の両方を予測する必要があり、それぞれ異なるパターンを持つ可能性があります。
    * **タイムシリーズAPI:** コンペティションはタイムシリーズAPI形式で行われ、テスト期間中に新しいデータ（翌日の天気予報など）が段階的に提供されます。これに対応するため、モデルを効率的に更新または再学習する戦略が必要です。

**データセットの形式 (Dataset Format)**

提供されるデータは、プロシューマーのエネルギー消費/生産量、顧客情報、気象データ、エネルギー価格など、多岐にわたります。

1.  **トレーニングデータ:**
    * `train.csv`: メインの時系列データ。
        * `county`, `is_business`, `product_type`: プロシューマーの区分を示すカテゴリ変数。
        * `is_consumption`: ターゲットが消費量(1)か生産量(0)かを示すフラグ。
        * `datetime`: タイムスタンプ（1時間ごと）。
        * `data_block_id`: 時間的なブロックID（データの連続性を示す）。
        * `target`: **ターゲット変数**。当該時間におけるエネルギー消費量または生産量 (kWhなど)。
        * `row_id`, `prediction_unit_id`: 識別子。
    * `client.csv`: 顧客に関する情報。特定の `data_block_id` における `county`, `is_business`, `product_type` ごとの顧客数 (`eic_count`) と合計設置容量 (`installed_capacity`)。
    * `gas_prices.csv`: ガスの価格情報。日付ごとの予測最低・最高価格。
    * `electricity_prices.csv`: 電力価格情報。日付ごとの予測価格。
    * `forecast_weather.csv`: 天気予報データ。緯度経度、予報起点時刻 (`origin_datetime`)、何時間先の予報か (`hours_ahead`)、および多数の気象変数（気温、露点、雲量、風速、日射量、降水量など）。
    * `historical_weather.csv`: 過去の天気データ。タイムスタンプ、緯度経度、および多数の気象変数。
    * `weather_station_to_county_mapping.csv`: 気象観測点の緯度経度と対応する郡 (county) のマッピング。
2.  **テストデータ (タイムシリーズAPI経由):**
    * `test.csv`: 予測対象期間のメタデータ（`row_id`, `prediction_unit_id`, `datetime`, `currently_scored` フラグなど）。`target` 列は含まれない。
    * 他のデータファイル (`client`, `gas_prices`, `electricity_prices`, `forecast_weather`, `historical_weather`) も、予測に必要な将来の情報を含んだ形で API を通じて提供される。
3.  **`sample_submission.csv`**:
    * 提出フォーマットのサンプル。
        * `row_id`: 予測対象行のID。
        * `target`: 予測されたエネルギー量（消費量または生産量）。

**評価指標 (Evaluation Metric)**

* **指標:** **MAE (Mean Absolute Error)** 平均絶対誤差。
* **計算方法:** 予測対象となる各行 (`row_id`) について、モデルの予測値 (`predicted`) と実際の値 (`actual`) の絶対差 `|predicted - actual|` を計算し、全ての予測対象行についてその平均値を取ります。
    * `MAE = (1/N) * Σ |predicted_i - actual_i|` （Nは予測対象行数）
* **意味:** 予測値が実際の値から平均してどれだけずれているかを絶対値で評価します。予測誤差の大きさを直接的に反映し、外れ値の影響を受けにくいという特徴があります。スコアは**低い**ほど予測精度が高いことを示します。

要約すると、このコンペティションは、多様な時系列データを活用してプロシューマーのエネルギー消費量と生産量を1時間ごとに予測する回帰タスクです。タイムシリーズAPI形式で進行し、性能はMAE（低いほど良い）によって評価されます。特徴量エンジニアリングとモデル更新戦略が鍵となります。

---

**全体的な傾向**

このエネルギー需要予測コンペティションでは、時系列予測の定番である**GBDT (勾配ブースティング決定木)**、特に **LightGBM** と **XGBoost** が上位解法の中心となりました。成功の鍵は、豊富なデータソースを活用した**精緻な特徴量エンジニアリング**と、タイムシリーズAPIに対応した**適切なモデル更新戦略**にありました。

**特徴量エンジニアリング**では、以下のような手法が広く用いられました。
* **ラグ特徴量:** ターゲット変数（消費量/生産量）や気象データ、価格データなどの過去の値（例: 24時間前、48時間前、1週間前など）を大量に生成。
* **移動統計量:** 過去の一定期間における各種変数の平均、標準偏差、最大、最小などを計算。
* **時間関連特徴量:** 時刻、曜日、月、年、祝日情報、およびこれらを周期的に表現するサイン/コサイン変換などが重要。
* **気象特徴量:** 予報データと過去データを組み合わせ、必要に応じて郡 (county) ごとに集約。日射量と設置容量 (`installed_capacity`) を組み合わせた特徴量も有効でした。
* **顧客情報特徴量:** 顧客数 (`eic_count`) や設置容量 (`installed_capacity`) をそのまま、またはターゲット変数との比率として利用。
* **インタラクション特徴量:** カテゴリ変数（`county`, `is_business`, `product_type`）同士の組み合わせや、これらと数値特徴量の組み合わせ。

**ターゲット変換**も重要なテクニックでした。生のターゲット値を予測する代わりに、以下のような変換後の値を予測し、最後に逆変換するアプローチが多く見られました。
* **ラグ差分:** `target - target_lag_N` （特に N=48 がよく使われた）
* **正規化:** 過去の平均値や設置容量などでターゲット値をスケーリング（例: `target / (installed_capacity + 1)`, `target / (target_lag_avg + 1)`）。

モデル構築においては、エネルギー**生産 (production)** と**消費 (consumption)** で**別々のモデルを学習**させるのが一般的でした。これにより、それぞれの特性に合わせた特徴量やモデルパラメータの最適化が可能になりました。

タイムシリーズAPI形式に対応するため、多くのチームが**オンライン学習/モデル更新**戦略を採用しました。テスト期間中に新しいデータが利用可能になるたびに（例: 毎日、数日ごと、週ごと）、特徴量を更新し、モデルを**再学習 (Retrain)** するアプローチが主流でした。

最終的な予測精度を高めるために、異なるモデルタイプ (LGBM, XGBoost, NN)、異なるターゲット変換、異なるハイパーパラメータ、異なるランダムシードで学習された**多数のモデルをアンサンブル**することが一般的でした。

**各解法の詳細**

**[1位](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/472793)**

* **アプローチ:** XGBoostとGRUのアンサンブル。豊富なラグ特徴量。
* **アーキテクチャ:** XGBoost (ターゲットx2, is_consumption x2), GRU (ターゲットx2)。
* **アルゴリズム:** GBDT, RNN。
* **テクニック:** 600個の特徴量（ラグ、時間、気象、顧客情報など）。ターゲット変換あり（ラグ差分/設置容量、設置容量正規化）。GRUは日次シーケンス入力、カテゴリ特徴埋め込み。オンライン更新あり（3回）。

**[5位](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/499938)**

* **アプローチ:** LightGBMアンサンブル (生産/消費 各3モデル)。特徴量削減とオンライン更新重視。
* **アーキテクチャ:** LightGBM。
* **アルゴリズム:** GBDT (VotingRegressorでアンサンブル)。
* **テクニック:** 特徴量削減 (生産75, 消費85)。ターゲット変換あり (生産: 設置容量正規化、消費: 過去7日平均正規化)。CV: 3 fold TimeSeriesSplit + Holdout。オンライン更新あり (9日ごと)。カスタム進化計算によるハイパラ/特徴量選択。

**[6位](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/499397)**

* **アプローチ:** LightGBM 大規模アンサンブル (160モデル)。日次ベースラインモデル予測を特徴量利用。
* **アーキテクチャ:** LightGBM。
* **アルゴリズム:** GBDT。
* **テクニック:** 4種の異なるターゲット変換。10シードx2ハイパーパラメータ設定。特徴量は公開ノートブックベース + **日次で再学習されるベースラインモデルの予測値**。LGBMモデル自体のオンライン再学習はなし。

**[7位](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/499649)**

* **アプローチ:** LGBM/XGBoostアンサンブル (トップ3モデル平均 x 2シード)。ARモデル残差をターゲットとする。
* **アーキテクチャ:** LightGBM, XGBoost。
* **アルゴリズム:** GBDT。
* **テクニック:** 生産/消費でモデル分割。**ターゲット変換**: 自己回帰 (AR) モデルを仮定し、その残差を予測 (生産: lag48、消費: lag48, 76, 92, ..., 336)。特徴量は公開ノートブックベース + ラグ特徴量。CV: 5 fold Sliding Window。オンライン学習なし。
