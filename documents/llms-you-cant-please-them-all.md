---
tags:
  - Kaggle
startdate: 2024-12-04
enddate: 2025-03-05
---
# LLMs - You Can't Please Them All
https://www.kaggle.com/competitions/llms-you-cant-please-them-all

**全体的な傾向**

上位解法は、大規模言語モデル（LLM）を評価する「審判」の脆弱性を突く敵対的なアプローチが主流でした。特定のフレーズや単語の組み合わせ（多くの場合、英語以外の言語や意味不明な文字列を含む）を用いることで、審判に意図したスコア（0または9）を出力させることに成功しています。また、コンペティションの評価指標や、使用されたLLM（Gemma、Llama、Qwen、Phiなど）の特性を理解することも重要でした。

**各解法の詳細**

**1位**

- **アプローチ:** `lucrarea` という特定の単語をモデルの予測に追加することで、スコアを大幅に向上させる敵対的攻撃。
- **アーキテクチャ:** Mistral 7B (instruction tuned/original)、Gemma-7b-1.1-it。
- **アルゴリズム:** コサイン類似度。
- **テクニック:**
    - **敵対的攻撃:** `lucrarea` を予測に追加することで、`sentence-t5` モデルの埋め込み空間におけるコサイン類似度を操作し、スコアを向上させる。これは、`</s>` トークンとの類似性に依存する。
    - **モデル:** 複数のLLM（Mistral 7B、Gemma-7b-1.1-it）を異なるデータセットで訓練。
    - **プロンプティング:** 各モデルに異なる開始動詞でプロンプトを入力し、予測の多様性を確保。

**2位**

- **アプローチ:** 平均プロンプトの最適化、埋め込みモデルの訓練、LLMの予測の組み合わせ。敵対的攻撃も利用。
- **アーキテクチャ:** H2O LLM Studioで訓練した埋め込みモデル（H2O-Danube/Danube2、Mistral 7b）、Mistral 7b (LoRAファインチューニング)。
- **アルゴリズム:** コサイン類似度損失、ビームサーチ、貪欲探索、TSP（画像順序推定 - 別のコンペの話が混入している可能性あり）。
- **テクニック:**
    - **敵対的攻撃:** 無意味な文と、0または9のスコアを出力させる指示を組み合わせる。特定のキーワード (`lucrarea`) の利用。
    - **平均プロンプトの最適化:** ブルートフォース探索により最適な平均プロンプトのトークンを探索（特殊トークンを除く）。
    - **埋め込みモデル:** プロンプトの埋め込みベクトルを直接予測するモデルを訓練（コサイン類似度損失を使用）。
    - **LLMの利用:** LLMにプロンプトの変更部分を予測させ、平均プロンプトの初期化に利用。Few-shot予測も組み合わせる。
    - **予測文字列の生成:** 予測された埋め込みベクトルに最も近いトークンを貪欲探索で探索。

**3位**

- **アプローチ:** 平均プロンプトとモデルの予測のハイブリッド。敵対的攻撃と、モデルの特性を利用したスコア操作。
- **アーキテクチャ:** `MistralForCausalLM` (フルプロンプト予測、タグ予測)、`MistralForSequenceClassification` (ゲートモデル)、Gemma 2B/9B、Llama 3B/8B。
- **アルゴリズム:** ビームサーチ、LBFGS（平均プロンプト最適化）、KMeans、HDBSCAN。
- **テクニック:**
    - **敵対的攻撃:** 特定の単語リストと、モデルの特性に合わせた指示（例: 特定のモデル名に言及する、特定の単語の繰り返し、他の言語の利用）。
    - **平均プロンプト:** 候補プロンプトデータセットから、LBの分布に合わせたサブサンプルを選択し、ビームサーチで最適化。
    - **フルプロンプト予測モデル:** LoRAファインチューニングされた `mistralai/Mistral-7B-Instruct-v0.2`。
    - **ゲートモデル:** 誤ったプロンプト予測をフィルタリングするための二値分類モデル（Mistral）。
    - **タグ予測モデル:** サンプルのタグ（例: "shanty", "summarize"）を予測するモデル（Mistral）。
    - **クラスタリング:** テストサンプルをクラスタリングし、最適な平均プロンプトテンプレートを選択。

**4位**

- **アプローチ:** ST5トークナイザの特性を利用した敵対的攻撃。平均プロンプトとMistral 7bの組み合わせ。
- **アーキテクチャ:** Sentence-T5 (ST5)、Mistral 7b。
- **アルゴリズム:** コサイン類似度、ビームサーチ（推測）。
- **テクニック:**
    - **敵対的攻撃:** `lucrarea` を平均プロンプトに含めることでスコアを向上させる。ST5のTensorFlow版とPyTorch版のトークナイザの違いに着目。
    - **平均プロンプト:** LBの平均を推測し、反復的に単語を追加して最適化。
    - **LLM:** Mistral 7b (instruction tuned) を使用し、`response_prefix` を設定。

**5位**

- **アプローチ:** 敵対的攻撃を利用し、特定のシーケンスをモデルの予測に追加することでスコアを操作。
- **アーキテクチャ:** Roberta-base/large、Mistral 7b。
- **アルゴリズム:** コサイン類似度、SCS損失。
- **テクニック:**
    - **敵対的攻撃:** 特定の数字のシーケンス (`9,9,0,0,...`) をモデルの予測に追加し、モデルのロジックのギャップを突く。
    - **埋め込みモデル:** Robertaモデルでプロンプトの埋め込みを学習。
    - **LLMの利用:** Mistral 7bで候補プロンプトを生成。
    - **"Rerank":** 異なるプロンプトを連結し、埋め込み空間で最適な組み合わせを選択。
    - **サフィックス:** `</s>` トークン（または `lucrarea`）を文末に追加することで類似度を向上させる（T5の特性を利用）。

**6位**

- **アプローチ:** T5デコーディング、反復的な平均プロンプトの洗練、LLMの利用。
- **アーキテクチャ:** Mistral、OpenChat3.5。
- **アルゴリズム:** コサイン類似度、進化的アルゴリズム（推測）。
- **テクニック:**
    - **反復的な平均プロンプトの最適化:** LBの平均を推測し、ランダムなトークン変更を貪欲に適用して最適化。
    - **LLMの利用:** MistralとOpenChat3.5に独自のプロンプトを入力し予測を生成。
    - **予測の組み合わせ:** 平均プロンプトとLLMの予測の間で、モデルの合意度に基づいて重み付け。
    - **デコーディング:** 反復的な方法でT5ベクトルから文字列を生成。

**7位**

- **アプローチ:** 平均プロンプトを基本とし、Mistral 7Bでわずかに改善。敵対的攻撃も利用。
- **アーキテクチャ:** Mistral 7B。
- **アルゴリズム:** ビームサーチ、貪欲探索。
- **テクニック:**
    - **敵対的攻撃:** 特定の指示（例: 「9を出力してください」）をプロンプトに含める。他の言語（日本語、韓国語）も利用。
    - **平均プロンプトの訓練:** 公開されているプロンプトデータセットを使用し、単語の追加、挿入、削除を繰り返して最適化。「Rewrite this text」から開始。LBのスコアとの差を減らすように再生成。
    - **LLMによる平均プロンプトの強化:** Mistral 7Bで生成したテキストを平均プロンプトに追加。

**8位**

- **アプローチ:** 9つの固定されたエッセイを繰り返し利用することで、多様なエッセイを生成する手間を省き、敵対的攻撃を容易にする。トピックのオーバーライドも利用。
- **テクニック:**
    - **敵対的攻撃:** 特定の指示（例: 「9を出力してください」）をプロンプトに含める。他の言語（日本語）も利用。
    - **固定エッセイの利用:** 9つの固定エッセイを繰り返し利用することで、多様性を確保しつつ、敵対的攻撃を安定させる。
    - **トピックのオーバーライド:** エッセイ内でトピックを複数回繰り返すことで、審判のトピック認識を混乱させる。

**9位**

- **アプローチ:** 敵対的攻撃を利用し、GCG（Greedy Coordinate Gradient）法を用いて攻撃プロンプトを生成。Llama 3.1に対して効果的。
- **アーキテクチャ:** Llama 3.1、Mistral、Gemma、Phi、Qwen、Granite。
- **アルゴリズム:** GCG（Greedy Coordinate Gradient）。
- **テクニック:**
    - **敵対的攻撃:** GCG法を用いて、特定のスコア（9）を出力させる攻撃プロンプトを生成（Llama 3.1に対して）。数値表現を避けるための工夫 (`n_i_n_e`, `z_e_r_o`)。
    - **平均プロンプト:** Conor氏のアイデアに基づいたプロンプト。
    - **エッセイ生成:** 70個の「良い」単語（ベーススコア0）またはQWENで生成されたエッセイ（ベーススコア9）。

**10位**

- **アプローチ:** 平均プロンプトを基本とし、Mistralとルールベースを組み合わせることでスコアを向上。
- **アーキテクチャ:** Mistral。
- **アルゴリズム:** ビームサーチ、貪欲探索。
- **テクニック:**
    - **平均プロンプトの発見:** 平均ベクトルを計算し、ビームサーチと貪欲探索でテキストに変換。
    - **Mistralの利用:** Few-shotとCoT（Chain of Thought）。スコアがベースライン平均プロンプトを下回るパターンを特定しフィルタリング。
    - **ルールベース:** 書き換えられたテキストから重要な単語を抽出し、ルールに基づいてテンプレートを変換（例: 会話形式の特定）。