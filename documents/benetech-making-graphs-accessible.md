---
tags:
  - Kaggle
startdate: 2023-04-22
enddate: 2023-06-20
---
# Benetech - Making Graphs Accessible

[https://www.kaggle.com/competitions/benetech-making-graphs-accessible](https://www.kaggle.com/competitions/benetech-making-graphs-accessible)

**概要 (Overview)**

- **目的:** このコンペティションの目的は、グラフ画像（棒グラフ、線グラフ、散布図、ドットプロットなど）から、その**種類を分類**し、グラフが表現する**データ系列（X軸とY軸の値のペア）を抽出**する機械学習モデルを開発することです。最終的には、視覚障碍を持つ人々がスクリーンリーダーなどを通じてグラフの内容を理解できるように、アクセシブルなデータを提供することを目指しています。
- **背景:** Benetechは、教育や雇用の機会均等を推進するためにテクノロジーを活用する非営利組織です。グラフは情報を効率的に伝える手段ですが、視覚障碍者にとってはアクセスが困難な場合が多くあります。このコンペティションは、AI技術を用いてデジタルグラフの画像から元データを抽出し、グラフ情報のアクセシビリティ向上に貢献することを目的としています。
- **課題:**
    - 多様なスタイルやフォーマットで描かれたグラフに対応する必要があること。
    - 低解像度、ノイズ、重なりなど、画像の品質が低い場合でも頑健に情報を抽出すること。
    - X軸とY軸のラベル、目盛り、データ点（棒、線、点）を正確に検出し、それらを正しく関連付けてデータ系列を再構築すること。
    - 特に散布図やドットプロットのように、個々の点の位置から数値を正確に推定することが難しいこと。
    - 抽出されたデータ系列を、指定されたテキスト形式（例: `x1|y1;x2|y2;...`）で正確に出力すること。
    - 訓練データ（手動抽出データと自動生成データ）とテストデータ（特にプライベートセットは異なるソース由来）の間のドメインギャップに対応し、高い汎化性能を持つモデルを構築すること。

**データセットの形式 (Dataset Format)**

提供される主なデータは、グラフ画像とそれに対応するアノテーション情報です。

1. **トレーニングデータ:**
    - `train/images/`: グラフ画像ファイル（JPEGまたはPNG形式）。
    - `train/annotations/`: 各画像に対応するJSON形式のアノテーションファイル。主な内容は以下の通り。
        - `"chart-type"`: グラフの種類を示す文字列 (`"vertical_bar"`, `"horizontal_bar"`, `"line"`, `"scatter"`, `"dot"`)。
        - `"text"`: グラフ内に含まれるテキスト要素のリスト。各要素にはテキスト内容 (`"text"`)、位置 (`"polygon"`)、役割 (`"role"`: 例 `tick_label`, `chart_title`) などが含まれる。
        - `"plot-bb"`: グラフの主要な描画領域（プロットエリア）を示すバウンディングボックス (`"x0"`, `"y0"`, `"x1"`, `"y1"`)。
        - `"axes"`: 軸情報。`"x-axis"` と `"y-axis"` を含み、それぞれに目盛りの位置と値 (`ticks`) のリストが含まれる。
        - `"data-series"`: **ターゲット変数**となるデータ系列。X値とY値のペア (`{"x": value, "y": value}`) のリスト形式。数値だけでなくカテゴリ文字列も含まれる。
    - トレーニングデータには、人間が抽出したデータ (`extracted`) と、プログラムで生成されたデータ (`generated`) の2種類が含まれます。
2. **テストデータ:**
    - `test/images/`: テスト用のグラフ画像ファイル。
    - `test/annotations/`: テスト画像に対応するアノテーションファイル。ただし、**`"data-series"` キーは含まれません**。参加者はこの `data-series` を予測します。
3. **`sample_submission.csv`**:
    - 提出フォーマットのサンプル。
        - `id`: 画像ファイル名（拡張子なし）。
        - `data_series`: 予測したデータ系列をセミコロン区切り、縦棒区切りで記述した文字列 (例: `Category A|10.5;Category B|25.0;Category C|15.8`)。
        - `chart_type`: 予測したグラフの種類。

**評価指標 (Evaluation Metric)**

- **指標:** **正規化されたレーベンシュタイン類似度 (Normalized Levenshtein Similarity)**
- **計算方法:**
    - 予測されたデータ系列文字列 (`Predicted`) と正解のデータ系列文字列 (`Ground Truth`) の間のレーベンシュタイン距離（編集距離）を計算します。レーベンシュタイン距離は、一方の文字列をもう一方の文字列に変形するために必要な最小の編集（挿入、削除、置換）回数です。
    - 次に、類似度を `Similarity = (max(len(Predicted), len(Ground Truth)) - LevenshteinDistance(Predicted, Ground Truth)) / max(len(Predicted), len(Ground Truth))` として計算します。
    - このスコアは0から1の範囲を取り、1が完全一致を示します。
    - 数値の比較には通常、わずかな許容誤差（例: 相対誤差1%または絶対誤差0.01）が考慮されますが、カテゴリ名などの文字列は完全に一致する必要があります。
    - 最終的なスコアは、各グラフタイプ（棒、線、散布図など）ごとに計算された平均類似度を、さらに全体の平均（または加重平均）をとって算出されます。
- **意味:** 予測されたデータ系列が、形式と内容の両面でどれだけ正解に近いかを評価します。編集距離を用いることで、完全に一致しなくても部分的な正しさや順序の近さが評価に反映されます。スコアは**高い**ほど、より正確にデータ系列を抽出できていると評価されます。

要約すると、このコンペティションは、グラフ画像からその種類とデータ系列を抽出し、指定されたテキスト形式で出力するタスクです。データは画像とJSONアノテーションで構成され、性能は予測文字列と正解文字列のレーベンシュタイン類似度（高いほど良い）によって評価されます。

---

**全体的な傾向**

このコンペでは、グラフ画像からデータ系列を抽出するという課題に対し、多くのチームが**2段階のアプローチ**を採用しました。まず**グラフ種類分類モデル**でグラフの種類を特定し、その後、種類に応じた**データ系列抽出モデル**を適用する流れです。

データ系列抽出の主流となったのは、**Vision Transformerベースの画像対テキストモデル**、特に **DePlot** や **Matcha** でした。これらのモデルは、画像を入力として受け取り、データ系列を表すテキスト文字列を直接生成することができます。

一方で、**散布図 (Scatter Plot)** や **ドットプロット (Dot Plot)** は、これらのEnd-to-Endモデルでは精度を出しにくいという課題がありました。そのため、これらのグラフタイプに対しては、**物体検出モデル** (YOLOX, YOLOv7, Mask R-CNNなど) を用いて個々の点、軸の目盛り、ラベルなどを検出し、それらの位置情報とOCR（光学的文字認識）結果を組み合わせてデータ系列を再構築するアプローチが有効でした。

また、提供されたデータセットだけではグラフの多様性が不十分であり、未知のデータに対する**汎化性能**が重要視されました。そのため、多くのチームが**独自に多様なスタイルのグラフ画像を生成（合成データ生成）**したり、ICDARなどの**外部データセット**を活用したり、**疑似ラベリング**を行ったりして、訓練データを拡充していました。

訓練においては、全体データでの事前学習後に特定のグラフタイプデータで**ファインチューニング**する多段階学習や、複数のモデルの結果を統合する**アンサンブル**もスコア向上に寄与しました。数値の丸め方や出力文字列のフォーマット調整といった**後処理**も重要な要素でした。

**各解法の詳細**

**[1位](https://www.kaggle.com/competitions/benetech-making-graphs-accessible/discussion/418786)**

- **アプローチ:** 2段階パイプライン。グラフ分類 → データ抽出。Bar/Line/DotはDePlot、Scatterは物体検出ベース。
- **アーキテクチャ:** 分類: ConvNeXt + Swin Transformer (アンサンブル)。データ抽出(Bar/Line/Dot): DePlot (グラフタイプ毎にファインチューニング)。データ抽出(Scatter): YOLOX (点検出) + CACHED (ラベル位置検出) + DePlot (ラベルテキスト読み取り)。
- **アルゴリズム:** 分類: 標準的な画像分類。DePlot: Image-to-Text生成。Scatter: 物体検出 + OCR + 座標計算。
- **テクニック:** 独自合成データ生成。ICDARデータセット活用 (手動修正含む)。DePlotの複数ステージ学習 (All Chart-type Train → Specific Chart-type Train)。DePlotの入力/出力形式を調整 (グラフタイプ除去、水平棒グラフの軸入れ替え)。Scatterでのラベルとテキストのマッピング。

**[2位](https://www.kaggle.com/competitions/benetech-making-graphs-accessible/discussion/418430)**

- **アプローチ:** 2段階学習パイプライン (Matcha-baseのみを使用)。Phase 1: ドメイン適応。Phase 2: 特化学習。
- **アーキテクチャ:** Matcha-base (Image-to-Text Transformer)。Phase 2ではScatter用と非Scatter用でモデルを分ける。
- **アルゴリズム:** Image-to-Text生成。
- **テクニック:** 大規模な独自合成データ生成 (Wikitables, 独自カテゴリ/数値生成、多様なグラフスタイル設定)。公開合成データ、疑似ラベルデータ、ICDARデータも使用。抽出データをオーバーサンプリング。数値の科学記数法表現。ヒストグラムを別タイプとして学習（後処理で統合）。AWP (Adversarial Weight Perturbation)。EMA (指数移動平均)。データ拡張。

**[3位](https://www.kaggle.com/competitions/benetech-making-graphs-accessible/discussion/418420)**

- **アプローチ:** 2段階パイプライン。分類 → データ抽出。Scatter/Dotは物体検出、Line/BarはMatcha。
- **アーキテクチャ:** 分類: NfNet-l2。データ抽出(Scatter/Dot): YOLOX (点検出) + CACHED (他要素検出) + OCR。データ抽出(Line/Bar): Matcha-base。
- **アルゴリズム:** 分類、物体検出、OCR、Image-to-Text生成。
- **テクニック:** 独自合成データ生成 (抽出データセットの値を再利用し多様なスタイルで描画)。抽出データは検証のみに使用し汎化性能を重視。Matchaの出力形式工夫。数値の小数点以下桁数調整。ヒストグラムを別タイプとして学習。複数モデルのアンサンブル (分類/Matcha)。Scatter/Dotでの後処理 (OCR/検出ミスへの頑健性向上)。

**[4位](https://www.kaggle.com/competitions/benetech-making-graphs-accessible/discussion/418604)**

- **アプローチ:** 2段階パイプライン。分類 → データ抽出。Scatterは物体検出、その他はDePlot。
- **アーキテクチャ:** データ抽出(Scatter): YOLOX (プロット領域検出) → YOLOX (点検出) + Matcha (軸ラベルOCR)。データ抽出(その他): DePlot。
- **アルゴリズム:** 物体検出、OCR、Image-to-Text生成。
- **テクニック:** 独自合成データ生成に注力 (多様なパターン、低品質シミュレーション、数値/記号区別など)。ICDARデータセット、公開合成データセットも使用。学習時に各データソースからランダムサンプリング。

**[5位](https://www.kaggle.com/competitions/benetech-making-graphs-accessible/discussion/418477)**

- **アプローチ:** 3段階学習パイプライン (Matcha-base) + Scatter用別プロセス。
- **アーキテクチャ:** Matcha-base (分類、全タイプ抽出、タイプ別ファインチューニング)。Scatter用: CACHED (領域/ラベル検出) + MobileNetV2 (角度分類) + VietOCR (テキスト認識) + Mask R-CNN + CoaT (マーカー検出)。
- **アルゴリズム:** Image-to-Text生成、物体検出、セマンティックセグメンテーション、画像分類、OCR。
- **テクニック:** 独自合成データ生成 (Chart Synthesizerベース、エラー分析に基づきパターン追加)。公開合成データも使用。3段階学習 (分類→全体抽出→タイプ別微調整)。ヒストグラムを別タイプとして学習。動的な数値丸め込み。

**[6位](https://www.kaggle.com/competitions/benetech-making-graphs-accessible/discussion/418466)**

- **アプローチ:** 単一DePlotモデル (複数シードブレンド) + Scatter用後処理 (U-Net)。
- **アーキテクチャ:** DePlot (二重デコーダー) + U-Net (EfficientNet-B7エンコーダー)。
- **アルゴリズム:** Image-to-Text生成、セマンティックセグメンテーション、NMS (Non Maximum Suppression)。
- **テクニック:** 抽出データの一部と難易度の高い生成データを使用。数値の丸め込み/バケツ化。二重デコーダー（順方向/逆方向シーケンスを学習、補助損失）。外部データ (PubMed) を疑似ラベルで使用。U-NetでScatterの点数を予測し、DePlotの予測と異なる場合に補正 (過剰なら末尾削除、不足なら平均値補完)。PixelDropout拡張。

**[7位](https://www.kaggle.com/competitions/benetech-making-graphs-accessible/discussion/418510)**

- **アプローチ:** マルチモデルパイプライン (End-to-Endモデル不使用、Kaggleデータのみ)。
- **アーキテクチャ:** グラフ分類器 (v2s) + テキスト検出器 + テキスト認識器 (事前学習済) + 物体検出器 (YOLOXなど) + セグメンテーションモデル + (フォールバック用DePlot)。
- **アルゴリズム:** 画像分類、テキスト検出/認識、物体検出、セマンティックセグメンテーション、ルールベース処理。
- **テクニック:** Kaggleデータのみ使用 (抽出データの一部を検証用)。各コンポーネントを個別に学習。テキスト検出/認識後の後処理 (直線フィルタリング)。目盛りとラベルのマッピング。値の推定 (最近傍の目盛り値と比較)。ヒストグラム判定 (バー領域のX軸占有率)。水平棒グラフは回転して垂直棒として処理。 longest increasing subsequenceを用いたY軸ラベルのノイズ除去。
