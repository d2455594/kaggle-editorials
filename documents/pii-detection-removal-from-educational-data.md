---
tags:
  - Kaggle
  - NLP
startdate: 2024-01-18
enddate: 2024-04-24
---
# PII Detection & Removal from Educational Data
https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data

**概要 (Overview)**

* **目的:** このコンペティションの目的は、教育関連のテキストデータ（例: 学生のエッセイ、ディスカッションフォーラムの投稿など）に含まれる**個人を特定できる情報（Personally Identifiable Information - PII）**の箇所を自動的に検出し、識別するモデルを開発することです。「Removal（除去）」とありますが、主眼は高精度な「Detection（検出）」にあることが多いです（検出された箇所を後処理でマスクまたは削除するため）。
* **背景:** 教育データを研究や分析目的で共有する際には、学生のプライバシーを保護するために慎重な匿名化が必要です。手作業でPIIを特定し編集する作業は時間がかかり、ミスも起こりやすいため、安全なデータ共有を促進するには自動化されたPII検出ツールが求められています。
* **課題:** PII（名前、メールアドレス、住所、電話番号、ID番号など）は様々な形式や文脈で現れるため、その検出は容易ではありません。特に教育データ特有のPII（学生IDなど）も考慮する必要があります。効果的なツールには、PIIでない有用なテキストを誤って検出しないこと（高い適合率 - Precision）と、存在するPIIを可能な限り見逃さないこと（高い検出率 - Recall）の両方が求められますが、プライバシー保護の観点からは特に後者（Recall）が重視される傾向があります。タスクは、事前に定義されたPIIカテゴリ（例: `NAME_STUDENT`, `EMAIL`, `ID_NUM`など）に対応するテキストのスパンを特定する**固有表現抽出（Named Entity Recognition - NER）**として扱われます。これは通常、各トークン（単語やサブワード）にPIIタグ（例: B-NAME, I-NAME, O）を割り当てる**トークン分類問題**としてモデル化されます。

**データセットの形式 (Dataset Format)**

提供される主なデータは、PII箇所がアノテーションされた教育関連のテキスト文書です。

1.  **トレーニングデータ (`train.json`, `train.jsonl` など):**
    * 複数の文書が含まれます。ファイル形式は、文書テキストとアノテーション（トークン位置、PIIタイプ）を一緒に格納するのに適した JSON または JSON Lines (`.jsonl`) である可能性が高いです。
    * 各文書には通常、以下が含まれます。
        * `document`: 文書の識別子。
        * `full_text`: 文書の全文テキスト。
        * `tokens`: テキストをトークン化したリスト（例: 単語のリスト）。
        * `trailing_whitespace`: 各トークンの後続空白の有無を示すリスト。
        * `labels`: **ターゲット変数**。各トークンに対応するPIIラベルのリスト。通常、BIO（Beginning, Inside, Outside）タギングスキーマが用いられます（例: `['O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', ...]`）。

2.  **テストデータ (`test.json`, `test.jsonl` など):**
    * トレーニングデータと同様の形式で `document`, `full_text`, `tokens`, `trailing_whitespace` を含みますが、`labels` は含まれません。
    * 参加者は、このテストデータに含まれる各文書の各トークンに対してPIIラベルを予測します。

3.  **`sample_submission.csv`**:
    * 提出フォーマットのサンプル。通常、`document`, `token` (トークンのインデックス), `label` (予測されたPIIラベル) の列を持ちます。`row_id` を使う形式もあります。

**評価指標 (Evaluation Metric)**

* **指標:** **Macro-averaged F5 Score (マクロ平均F5スコア)**
* **計算方法:**
    1.  モデルはテストデータの各トークンに対してPIIラベルを予測します。
    2.  これらのトークンレベルの予測を集約して、完全なPIIエンティティのスパン（例: 連続する `B-NAME_STUDENT`, `I-NAME_STUDENT` トークン）を特定します。
    3.  予測されたエンティティスパンを、正解のエンティティスパンと比較します（スパンの境界とエンティティタイプの両方が一致する必要がある）。
    4.  各PIIエンティティタイプ（`NAME_STUDENT`, `EMAIL` など）ごとに、適合率（Precision）、検出率（Recall）、および F5 スコアを計算します。
        * F5スコアは、適合率よりも**検出率（Recall）を5倍重視**する Fベータスコアの一種です: F5 = (1 + 5²) * (Precision * Recall) / (5² * Precision + Recall) = 26 * (Precision * Recall) / (25 * Precision + Recall)
    5.  最後に、全てのPIIタイプについて計算されたF5スコアを単純平均（マクロ平均）したものが、最終的な評価スコアとなります。
* **意味:** F5スコアは、PII検出タスクにおいて「見逃しを極力減らす」という目的を強く反映した指標です。PIIでないものを誤って検出してしまう（適合率の低下）ことよりも、PIIを見逃してしまう（検出率の低下）ことに対して、はるかに大きなペナルティを与えます。マクロ平均は、データセット内での出現頻度に関わらず、各PIIタイプを平等に評価します。F5スコアが**高い**ほど、検出率を重視した目標において、モデルの性能が良いと評価されます。

要約すると、このコンペティションは、教育データ内のPIIを検出する固有表現抽出（NER）タスクであり、特に見逃しを最小限に抑えることが重視されます。データはPIIがアノテーションされた文書（JSON形式が主）で、性能は各PIIタイプでRecallを強く重視して計算されたF5スコアをマクロ平均した値（高いほど良い）によって評価されます。

---

**全体的な傾向:**

上位解法は、Transformerベースの言語モデル（特にDeBERTa-v3 large）のファインチューニングが中心でした。外部データ（特にAI生成データ）の活用、カスタムヘッドの設計、データ拡張、そしてルールベースのポストプロセッシングが重要なテクニックとして用いられました。また、トークナイザの特性を理解し、それに対応した処理を行うこともスコア向上に貢献しました。

**各解法の詳細:**

**1位**

- **アプローチ:** 多様で大規模なAI生成データセットを活用したDeBERTaアンサンブル。カスタムモデル（Multi-Sample Dropout、Bilstmレイヤー）、知識蒸留、データ拡張、そしてルールベースのポストプロセッシング。
- **アーキテクチャ:** DeBERTa-v3 large/base、カスタムヘッド（Multi-Sample Dropout、Bilstmレイヤー）。
- **アルゴリズム:** ロス関数（CrossEntropyLoss、KLDivLoss）、オプティマイザ（AdamW）。
- **テクニック:**
    - **データ:** 外部データセット（nbroad、mpware、自作）、データ拡張（名前の入れ替え）。
    - **モデリング:** DeBERTaのバリエーション、知識蒸留（複数の教師モデル）、重み付き投票アンサンブル。
    - **ポストプロセッシング:** 閾値調整、`NAME_STUDENT` のフィルタリング（title-cased、数字/アンダースコアなし）、同一文書内でのラベル伝播、`PHONE_NUM` を `ID_NUM` に変換、`STREET_ADDRESS` の修正、`USERNAME` の修正、短すぎる/長すぎる予測の除去、`URL_PERSONAL`、`EMAIL` のフィルタリング、正規表現。

**2位**

- **アプローチ:** DeBERTa-v3-largeモデルのアンサンブルと、pre/post処理。Kaggle-OnlyデータとPersuadeデータの特性を考慮した2段階学習。
- **アーキテクチャ:** DeBERTa-v3-large。カスタム分類ヘッド。
- **アルゴリズム:** BCEWithLogitsLoss（順序回帰）。
- **テクニック:**
    - **データ:** Kaggleデータ、nbroadの生成データセット（低重み）。
    - **前処理:** サブストリング（単語、句読点、空白）に基づくトークナイズ、B-/I-プレフィックスの除去、空白の無視。
    - **学習:** 2段階学習（Kaggle-Persuadeで事前学習後、Kaggle-Onlyでファインチューニング）、MLM事前学習（10エポック）。
    - **後処理:** `NAME_STUDENT` のフィルタリング（title-cased、長さ1より大きい）、同一文書内でのラベル伝播、`\n` を `STREET_ADDRESS` として予測。
    - **アンサンブル:** 6つのDeBERTa-v3-largeモデルの投票。

**3位**

- **アプローチ:** MLM事前学習済みDeBERTaと、データセットの特性に基づいた2段階ファインチューニング。ソフトラベリング、敵対的サンプリング（データセット改善）。
- **アーキテクチャ:** DeBERTa-v3-base、DeBERTa-v3-large。
- **アルゴリズム:** BCE損失。
- **テクニック:**
    - **データ:** mpwareデータセットで事前学習、競技データとnbroadデータセットでファインチューニング。
    - **データ前処理:** 改行文字を特殊トークンに変換。
    - **CV戦略:** Prompt name/scoreに基づいたMultilabelstratifiedkfold。Data AとData Bを別々に分割。
    - **モデルと学習:** MLM事前学習、レイヤー凍結（9層または6層）。回帰とBCE損失を使用。2段階学習でソフトラベリングを活用。
    - **ポストプロセッシング:** `O` ラベルの閾値処理、OOF予測に基づいた偽陽性フィルタリング（短すぎる予測、教師名、Mr/Mrs/Drなど）、同一文書内でのラベル伝播、`PHONE_NUM` を `ID_NUM` に変換、URL/EMAILの除去、正規表現。

**4位**

- **アプローチ:** Llama3 🦙 70Bをベースモデルとしたアンサンブル。データソースのタグ付け、データソース分類ヘッドの追加、非Persuadeデータのスコアに基づく早期停止。動的マイクロバッチ照合、高速なDeBERTa実装。
- **アーキテクチャ:** DeBERTa V3 Large、Qwen2-1.5B-Instruct、Llama3 70B。
- **アルゴリズム:** Focal Loss。
- **テクニック:**
    - **データ:** 公式データ、33kデータ、nbroadデータセット。LLaMA3 70Bで生成したデータ。
    - **データソースの区別:** 入力にデータソースのタグを追加。データソース分類ヘッドを追加。
    - **早期停止:** 非Persuadeデータのスコアに基づいて早期停止。
    - **データ生成:** ペルソナ、ツール、PII情報を用いたLLMによるデータ生成。偽陽性サンプルの言い換え。
    - **後処理:** STUDENT_NAMEのフィルタリング（教師名、フィクションキャラクター）、正規表現による名前/IDのフィルタリング、特定のinstructor名の除去、XGBoostによる検証。
    - **その他:** Dynamic Micro Batch Collation、高速なDeBERTa実装。

**5位**

- **アプローチ:** 170万件のトレーニング例とドメイン適応。教師モデル（DeBERTa、Mamba）でテストデータをラベル付けし、その予測を模倣するように生徒モデル（DeBERTa）を訓練する。
- **アーキテクチャ:** DeBERTa-v3-large、Mamba-790m (教師モデル)、DeBERTa-v3-large (生徒モデル)。
- **アルゴリズム:** SCS損失（教師モデル）、MSE/MAE損失（生徒モデル）。カットミックス。
- **テクニック:**
    - **データ:** PERSUADE essays、Uncopyrighted Pile Completions、SlimPajama Completions、Tricky Crawl。疑似ラベリング（ソフトラベル）。
    - **データ拡張:** バグのあるスペルチェック、ブラックリスト文字の削除、タイポの追加、ランダムな大文字化、文の入れ替え。カットミックス（p=1.0）。
    - **ドメイン適応:** 短いコンテキストの生徒モデルによる教師アンサンブルの予測の模倣。
    - **アンサンブル:** 異なるバックボーンのアンサンブル、TTAライクなアンサンブル。

**6位**

- **アプローチ:** 重み付き平均アンサンブル（DeBERTaモデル）。DeBERTaトークナイザからSpacyトークナイザへのマッピング。Mistral-v02で作成した追加データセットの利用。エラー分析に基づいた後処理。
- **アーキテクチャ:** DeBERTa-v3-large、DeBERTa-v3-base、カスタムヘッド（トークンマッピング機能付き）。
- **アルゴリズム:** Focal Loss。
- **テクニック:**
    - **カスタムヘッド:** DeBERTaトークンからSpacyトークンへの予測確率のマッピング。
    - **データ:** 競技データ、公開データセット、Mistral-7B-Instruct-v0.2で生成したデータセット。
    - **損失:** DeBERTaトークン損失、文字損失、Spacyトークン損失、開始/終了位置損失。
    - **後処理:** 空白文字のラベル修正、`\n` の処理、同一エッセイ内の `NAME_STUDENT` の統一。

**7位**

- **アプローチ:** 14モデルのアンサンブルとポストプロセッシング。公開されている事前学習済みモデルの利用。
- **アーキテクチャ:** DeBERTa-v3-large（様々な事前学習済みモデル）。
- **アルゴリズム:** 不明（write-upに詳細な記述なし）。
- **テクニック:**
    - **アンサンブル:** 複数の公開モデルの重み付き投票。短いテキストにはより多くのモデルを使用。
    - **ポストプロセッシング:** ラベルごとの異なる閾値、`NAME_STUDENT` のフィルタリング（title-cased、数字/アンダースコアなし）、`B-` トークンの修正（`I-` が続かない場合）、アドレスのラベル追加（改行など考慮）。

**9位**

- **アプローチ:** DeBERTa v3 largeのアンサンブル（レイヤードロップアウト、マルチサンプルドロップアウト、LoRA）。Mixtral 8x7bで作成した改善版データセットの利用。手動で修正したtrain.json。
- **アーキテクチャ:** DeBERTa v3 large、DeBERTa v2 xlarge (LoRA)。
- **テクニック:**
    - **データ:** Mixtral 8x7bで作成したデータセット（引用、チームメイト名、URLなど追加）、手動で修正したtrain.json。
    - **学習:** 4フォールドで設定を見つけ、全データで学習。エポックごとに名前を入れ替えるコールバック。
    - **ポストプロセッシング:** `NAME_STUDENT` のフィルタリング（title-cased、英字とドットのみ）、dr/mr/missなどの除去、同一文書内の名前の統一、`I-` の修正、URL/EMAILの除去、電話番号の正規表現。