---
tags:
  - Kaggle
  - LLM
  - NLP
startdate: 2023-11-01
enddate: 2024-01-23
---
# LLM - Detect AI Generated Text
https://www.kaggle.com/competitions/llm-detect-ai-generated-text

**概要 (Overview)**

* **目的:** このコンペティションの目的は、与えられたテキストが人間によって書かれたものか、それとも大規模言語モデル（Large Language Model - LLM）によって生成されたものかを正確に識別するモデルを開発することです。
* **背景:** LLMの能力が向上し、その利用が広がるにつれて、AIによって生成されたテキストを人間が書いたものと区別する必要性が高まっています。これは、学術的な誠実性（AIが書いたレポートの検出）、偽情報対策（ボットによるコンテンツ生成の特定）、透明性の確保など、様々な文脈で重要となっています。
* **課題:** 現代のLLMは非常に流暢で人間らしい文章を生成できるため、その識別は困難です。モデルは、AI生成テキストに特有の微妙な統計的パターン、文体の癖、その他の手がかりを見つけ出す必要があります。また、検出を回避しようとする試み（Adversarial Attack）に対しても、ある程度の頑健性を持つことが望まれます。タスクは、与えられたテキストがAI生成か人間によるものかを分類する**二値分類問題**です。

**データセットの形式 (Dataset Format)**

提供される主なデータは、人間が書いたテキストとAIが生成したテキストのサンプルです。

1.  **トレーニングデータ:**
    * 人間が書いたエッセイと、複数の（可能性として7つ以上の）異なるLLMによって生成された可能性のあるエッセイが含まれます。
    * 通常、CSVファイル (`train_essays.csv` など) で提供され、各行が1つのテキストサンプルに対応します。
    * 列には、`id`（テキストの識別子）、`prompt_id`（もし特定の課題に応じた文章であれば）、`text`（テキスト本文）、そして**ターゲット変数**である `generated`（人間が書いた場合は0、AI生成の場合は1）が含まれます。
    * **重要な注意点:** このコンペティションでは、提供されるトレーニングデータセットのサイズが意図的に**制限**されている可能性があります。そのため、高性能なモデルを構築するには、**外部のデータセットを追加で利用することが推奨または必要**となる場合が多いです。

2.  **テストデータ (`test_essays.csv` など):**
    * トレーニングデータと同様の形式で `id`, `prompt_id`, `text` を含みますが、`generated` ラベルは含まれません。
    * 参加者は、このテストデータに含まれるテキストがAI生成（1）か人間によるもの（0）かを予測します。

3.  **課題（プロンプト）データ (`train_prompts.csv` など):**
    * エッセイが書かれる元となった課題（プロンプト）の情報が含まれる場合があります。

4.  **`sample_submission.csv`**:
    * 提出フォーマットのサンプル。通常、`id` と、予測された `generated` の値（通常はAI生成である確率）の列を持ちます。

**評価指標 (Evaluation Metric)**

* **指標:** **Area Under the ROC Curve (AUC) (ROC曲線下面積)**
* **計算方法:** AUCは、二値分類モデルの性能を評価するための標準的な指標です。モデルが、ランダムに選んだAI生成テキスト（正例）を、ランダムに選んだ人間作成テキスト（負例）よりも「AIらしい」と正しくランク付けする確率を表します。分類の閾値を様々に変化させたときの、真陽性率（True Positive Rate）と偽陽性率（False Positive Rate）の関係をプロットしたROC曲線の下側の面積として計算されます。
    * スコアの範囲は 0 から 1 です。
        * 1: 完全な分類
        * 0.5: ランダムな推測と同等
* **意味:** AUCは、クラス間の分離能力を総合的に評価する指標であり、データセットのクラス不均衡の影響を受けにくいという特徴があります。このコンペティションでは、AUCが高いほど、モデルがAI生成テキストと人間が書いたテキストを正確に区別できていると評価されます。

要約すると、このコンペティションは、与えられたテキストが人間によるものかAI生成かを判定する二値分類タスクです。データはテキストサンプルとそのラベル（人間=0, AI=1）で構成されますが、外部データの利用が鍵となる可能性があります。性能は、分類能力を総合的に示すAUC（高いほど良い）によって評価されます。

---

**全体的な傾向:**

このコンペでは、エッセイが人間によって書かれたものか、AIによって生成されたものかを検出することが課題です。上位解法では、大規模言語モデル（LLM、特にDeBERTa-v3 largeやMistral 7b）のファインチューニングと、伝統的な機械学習手法（TF-IDF、SVM、ランダムフォレスト、GBDT）の組み合わせが一般的です。敵対的生成、データ拡張、疑似ラベリング、アンサンブル学習、そして特に、多様で大規模な学習データの作成が重要なテクニックとして用いられました。

**各解法の詳細:**

**1位**

- **アプローチ:** 多様で大規模なAI生成エッセイデータセットの作成に重点を置くことで、汎化性能の高いモデルを目指す。モデル自体よりもデータセットの質が重要であると考える。
- **アーキテクチャ:** Mistral 7b (Q)LoRAファインチューニング、DeBERTa-v3 (分類、カスタムトークナイザ+MLM+疑似ラベル、ランキング)、Ghostbuster (Llama 7b, Tiny Llama 1.1B)、Ahmetの教師なしアプローチのバリエーション。
- **アルゴリズム:** (Q)LoRA、BCE損失、ペアワイズ損失、SVM、ランダムフォレスト。
- **テクニック:**
    - **データセット:** Persuadeコーパス全体、OpenAI GPT2 output dataset、ELLIPSE corpus、NarrativeQA、wikipedia、NLTK Brown corpus、IMDB映画レビューなどの多様な人間テキストと、様々なLLM（独自、オープンソース、ファインチューニング済み）で生成したテキストを組み合わせた大規模データセット。データ拡張（スペルチェック、文字の削除/挿入/置換、同義語置換、難読化、バックトランスレーション、ランダムな大文字化、文の入れ替え）も実施。
    - **モデリング:** 複数のLLMのファインチューニング、DeBERTa-v3の様々なタスクへの適用、Ghostbuster（トークン確率ベース）、教師なしアプローチの修正実装。
    - **アンサンブル:** ランク平均を使用。Mistral-7bモデルに高い重みを設定。

**2位**

- **アプローチ:** 大規模で多様なAI生成テキストデータセットでの事前学習（pretraining）を重視し、その後、タスク固有のデータでファインチューニング（finetuning）を行う。
- **アーキテクチャ:** DeBERTa-v3-large、DeBERTa-large。
- **アルゴリズム:** 不明（write-upに詳細な記述なし）。
- **テクニック:**
    - **事前学習:** SlimPajamaデータセットからLLMで生成した約50万件の人間/AIテキストペアでDeBERTaモデルを事前学習。
    - **ファインチューニング:** Persuadeコーパスの学生エッセイで言語モデル（LM）ファインチューニング（llm-studioを使用）。DAIGT-V4-TRAIN-DATASETでもファインチューニング。
    - **アンサンブル:** 複数のDeBERTaモデルのアンサンブル。TF-IDFカーネルとのブレンドも試行。

**3位**

- **アプローチ:** TF-IDFパイプラインとDeBERTa-v3-largeモデルのアンサンブル。大規模なAI生成テキストデータセットでの事前学習と、敵対的サンプリングによるデータセットの改善。
- **アーキテクチャ:** DeBERTa-v3-base、DeBERTa-v3-large、CatBoost、LightGBM、Lightautoml、Shallow NN。
- **アルゴリズム:** TF-IDF、CatBoost、LightGBM、Lightautoml、Ridge回帰（アンサンブル）、UMAP（後処理）。
- **テクニック:**
    - **データ前処理:** 難読化解除（一定以上のエラーがあるテキストのみ）、不要な記号の削除、エンコーディングの正規化。
    - **LLM生成データ:** 厳選された約11kの生成/言い換え/部分的に言い換えられたエッセイでモデルを訓練。敵対的サンプリング（誤予測サンプルをデータセットに追加）。PileとSlimPajamaデータセットから約100万件のテキストを生成。
    - **TF-IDFパイプライン:** 既存の公開ノートブックを調整（イテレーション数の増加、疑似ラベルの追加）。
    - **アンサンブル:** TF-IDFとLLMモデルの予測を2段階で重み付け平均。
    - **後処理:** プロンプトIDごとにUMAPを用いて距離を計算し、予測を調整（クリッピング）。

**4位**

- **アプローチ:** 複数のモデル（古典的ML、LLMベース）を組み合わせたアンサンブル。データソース（Persuadeと非Persuade）の区別を考慮した学習戦略。
- **アーキテクチャ:** 線形モデル、勾配ブースティングモデル、Mistral-7bベースの特徴量抽出器、Longformer、DeBERTa-v3。
- **アルゴリズム:** TF-IDF、線形モデル、勾配ブースティング、Mistral-7b（特徴量抽出）、Longformer、DeBERTa-v3。
- **テクニック:**
    - **古典的ML:** より広いngram範囲、特徴量空間の制限、追加のトークナイザー前処理ステップ、DAIGT V2トレーニングデータ（後処理あり）、人工的なタイポの導入（ランダム）。
    - **LLMアプローチ:** Mistral-7bベースの特徴量、TF-IDFアプローチで疑似ラベル化されたテストセットでの再訓練。
    - **Transformer:** Longformer（ターゲットをデータソースとして訓練）、DeBERTa-v3（大規模な公開データで事前学習）。
    - **アンサンブル:** 各モデルに個別の重みを設定（公開LBスコアに過度に依存せず、バランスを重視）。動的マイクロバッチ照合、高速なDeBERTa実装。

**6位**

- **アプローチ:** 事前学習済みLLM（phi-2）を用いてエントロピーベースの合成特徴量を計算し、人間が書いたエッセイのみでOne-Class SVMを訓練する教師なしアプローチ。
- **アーキテクチャ:** phi-2 (LLM)、One-Class SVM。
- **アルゴリズム:** One-Class SVM。
- **テクニック:**
    - **特徴量抽出:** 事前学習済みLLM（phi-2）を用いてエントロピーベースの合成特徴量を計算。
    - **モデル訓練:** 人間が書いたエッセイのみを訓練データとしてOne-Class SVMを訓練。
    - **データ:** DAIGT-V4-TRAIN-DATASETを使用して最適な特徴量を選択。

**7位**

- **アプローチ:** 指示チューニングされていないモデル（Falcon-7B、Mistral-7B、Llama2-7B）のみを使用してAI生成データを生成し、そのデータでDeBERTa-v3-largeをファインチューニング。
- **アーキテクチャ:** DeBERTa-v3-large。
- **アルゴリズム:** 不明（write-upに詳細な記述なし）。
- **テクニック:**
    - **AI生成データ:** 指示チューニングされていないLLMを用いて、温度、top p、頻度ペナルティを調整しながら非エッセイテキストとエッセイを生成。Persuade 2.0のエッセイをプロンプトとして利用し、生成されたテキストをフィルタリング。
    - **ファインチューニング:** 生成されたデータセットでDeBERTa-v3-largeをファインチューニング。
    - **後処理:** 予測値が特定のパーセンタイル範囲内にある場合に、基本的なTF-IDF + SGDモデルの出力で置換。

**8位**

- **アプローチ:** 言語モデルのperplexity（PPL）とGLTR（Giant Language Model Test Room）の言語学的特徴量を組み合わせて、VotingClassifierを訓練する。
- **アーキテクチャ:** GPT-2 (small, medium, large)、VotingClassifier。
- **アルゴリズム:** Perplexity、GLTR (Test-2特徴量)、VotingClassifier。
- **テクニック:**
    - **特徴量抽出:** GPT-2モデルを用いてテキストレベルと文レベルのPPLを計算。GLTRを用いてTop-10、Top-100、Top-1000、1000+ランクのトークン数を計算。
    - **データ:** daigt v2データセットとstarblasters8氏が共有した800kデータセットを使用。
    - **モデル訓練:** 上記の特徴量を組み合わせてVotingClassifierを訓練。

**9位**

- **アプローチ:** TF-IDFベースのパイプラインとBERTベースのパイプラインのアンサンブル。多様なデータセットと難読化解除パイプラインを特徴とする。
- **アーキテクチャ:** TF-IDF、DeBERTa-v3-large、RoBERTa。
- **アルゴリズム:** TF-IDF、DeBERTa-v3-large、RoBERTa。
- **テクニック:**
    - **データセット:** 多様なプロンプトとサイズの異なるモデル（~20万から~70万サンプル）で慎重にキュレーションされたデータセット。
    - **難読化解除:** 統計ベースとリバースエンジニアリングベースの難読化解除パイプライン。
    - **後処理:** クラスタリングベースの後処理。
    - **BERTベースパイプライン:** 2つのDeBERTa-v3-largeモデルと1つのRoBERTaモデルを、異なるが重複する多様なデータセットのバリアントで訓練。