---
tags:
  - Kaggle
url: https://www.kaggle.com/competitions/llm-prompt-recovery
startdate: 2024-02-28
enddate: 2024-04-17
---
**全体的な傾向:**

このコンペでは、T5モデルによってエンコードされたプロンプトの埋め込みベクトルから、元のプロンプトテキストを復元することが課題です。上位解法では、「平均プロンプト」と呼ばれる、多くのプロンプトに共通する要素を捉えた固定のプロンプトをベースラインとし、そこに大規模言語モデル（LLM、特にMistral 7BやGemma）の予測や、特定のキーワード（`lucrarea`）を組み合わせるアプローチが主流でした。埋め込み空間での操作や、検索アルゴリズムを用いたプロンプトの最適化、そして、T5モデルのトークナイザの特性を悪用するテクニックも重要な要素となりました。

**各解法の詳細:**

**1位**

- **アプローチ:** 敵対的攻撃（adversarial attack）を利用し、特定のキーワード（`lucrarea`）をモデルの予測に追加することでスコアを大幅に向上させる。
- **アーキテクチャ:** Mistral 7B (instruction tuned/original)、Gemma-7b-1.1-it。
- **アルゴリズム:** コサイン類似度。
- **テクニック:**
    - **敵対的攻撃:** モデルの予測に特定の文字列（`lucrarea`を含む）を追加することで、T5モデルの埋め込み空間におけるコサイン類似度を操作し、スコアを向上させる。これは、T5のトークナイザの特殊トークン (`</s>`) の処理方法と、`lucrarea` が `</s>` に類似した埋め込みを持つことに依存する。
    - **モデル:** 複数のLLM（Mistral 7B、Gemma-7b-1.1-it）を異なるデータセットで訓練。
    - **プロンプティング:** 各モデルに異なる開始動詞でプロンプトを入力し、予測の多様性を確保。
    - **アンサンブル:** 各モデルの予測を連結。

**2位**

- **アプローチ:** 平均プロンプトの最適化、埋め込みモデルの訓練、LLMの予測の組み合わせ。
- **アーキテクチャ:** H2O LLM Studioで訓練した埋め込みモデル（H2O-Danube/Danube2、Mistral 7b）、Mistral 7b (LoRAファインチューニング)。
- **アルゴリズム:** コサイン類似度損失、ビームサーチ、貪欲探索、TSP（画像順序推定 - 別のコンペの話が混入している可能性あり）。
- **テクニック:**
    - **平均プロンプトの最適化:** ブルートフォース探索により最適な平均プロンプトのトークンを探索（特殊トークンを除く）。
    - **埋め込みモデル:** プロンプトの埋め込みベクトルを直接予測するモデルを訓練（コサイン類似度損失を使用）。
    - **LLMの利用:** LLMにプロンプトの変更部分を予測させ、平均プロンプトの初期化に利用。Few-shot予測も組み合わせる。
    - **予測文字列の生成:** 予測された埋め込みベクトルに最も近いトークンを貪欲探索で探索。
    - **アンサンブル:** Few-shot予測、LLM予測、平均プロンプト、最適化された埋め込み文字列を組み合わせる。

**3位**

- **アプローチ:** 平均プロンプトテンプレート、フルプロンプト予測モデル、ゲートモデル（誤予測フィルタリング）、タグ予測モデル、クラスタリングモデルの組み合わせ。
- **アーキテクチャ:** `MistralForCausalLM` (フルプロンプト予測、タグ予測)、`MistralForSequenceClassification` (ゲートモデル)。
- **アルゴリズム:** ビームサーチ、LBFGS（平均プロンプト最適化）、KMeans、HDBSCAN。
- **テクニック:**
    - **平均プロンプト:** 候補プロンプトデータセットから、LBの分布に合わせたサブサンプルを選択し、ビームサーチで最適化。
    - **フルプロンプト予測モデル:** LoRAファインチューニングされた `mistralai/Mistral-7B-Instruct-v0.2`。プロンプト候補、プロンプトのバリエーション、入力テキストをLLMで生成し、クラスタリングでバランス調整。
    - **ゲートモデル:** 誤ったプロンプト予測をフィルタリングするための二値分類モデル（Mistral）。
    - **タグ予測モデル:** サンプルのタグ（例: "shanty", "summarize"）を予測するモデル（Mistral）。
    - **クラスタリング:** テストサンプルをクラスタリングし、最適な平均プロンプトテンプレートを選択。

**4位**

- **アプローチ:** ST5トークナイザの特性を利用した敵対的攻撃。平均プロンプトとMistral 7bの組み合わせ。
- **アーキテクチャ:** Sentence-T5 (ST5)、Mistral 7b。
- **アルゴリズム:** コサイン類似度、ビームサーチ（推測）。
- **テクニック:**
    - **敵対的攻撃:** ST5のTensorFlow版とPyTorch版のトークナイザの違いに着目し、`lucrarea` を平均プロンプトに含めることでスコアを向上させる。`lucrarea` は `</s>` トークンと埋め込み空間で類似している。
    - **平均プロンプト:** LBの平均を推測し、反復的に単語を追加して最適化。
    - **LLM:** Mistral 7b (instruction tuned) を使用し、`response_prefix` を設定。

**5位**

- **アプローチ:** 170万件のトレーニング例とドメイン適応。教師モデル（DeBERTa、Mamba）でテストデータをラベル付けし、その予測を模倣するように生徒モデル（DeBERTa）を訓練する。
- **アーキテクチャ:** DeBERTa-v3-large、Mamba-790m (教師モデル)、DeBERTa-v3-large (生徒モデル)。
- **アルゴリズム:** コサイン類似度、SCS損失（教師モデル）、MSE/MAE損失（生徒モデル）。
- **テクニック:**
    - **データ生成:** vLLMを用いて多様なLLM（Gemma、deepseek、ChatGPT4など）から約50万件の入力サンプルを生成。公開データセットも利用。
    - **教師モデル推論:** 長いコンテキスト（1024トークン）の教師モデル（DeBERTa、Mamba）でテストデータをラベル付け（ソフトラベル）。
    - **生徒モデル訓練:** 短いコンテキスト（128/256文字）の生徒モデル（DeBERTa）に教師アンサンブルの予測を模倣させるようにファインチューニング。
    - **生徒モデル推論:** 重複するチャンクで予測を行い、平均化。

**6位**

- **アプローチ:** T5デコーディング、反復的な平均プロンプトの洗練、LLMの利用。
- **アーキテクチャ:** Mistral、OpenChat3.5。
- **アルゴリズム:** コサイン類似度、進化的アルゴリズム（推測）。
- **テクニック:**
    - **反復的な平均プロンプトの最適化:** LBの平均を推測し、ランダムなトークン変更を貪欲に適用して最適化。
    - **LLMの利用:** MistralとOpenChat3.5に独自のプロンプトを入力し予測を生成。
    - **予測の組み合わせ:** 平均プロンプトとLLMの予測の間で、モデルの合意度に基づいて重み付け。
    - **デコーディング:** 反復的な方法でT5ベクトルから文字列を生成。

**7位**

- **アプローチ:** 主に平均プロンプトに基づき、Mistral 7Bでわずかに改善。
- **アーキテクチャ:** Mistral 7B。
- **アルゴリズム:** ビームサーチ、貪欲探索。
- **テクニック:**
    - **平均プロンプトの訓練:** 公開されているプロンプトデータセットを使用し、単語の追加、挿入、削除を繰り返して最適化。「Rewrite this text」から開始。LBのスコアとの差を減らすように再生成。
    - **LLMによる平均プロンプトの強化:** Mistral 7Bで生成したテキストを平均プロンプトに追加。

**10位**

- **アプローチ:** 平均プロンプトを基本とし、Mistralとルールベースを組み合わせることでスコアを向上。
- **アーキテクチャ:** Mistral。
- **アルゴリズム:** ビームサーチ、貪欲探索。
- **テクニック:**
    - **平均プロンプトの発見:** 平均ベクトルを計算し、ビームサーチと貪欲探索でテキストに変換。
    - **Mistralの利用:** Few-shotとCoT（Chain of Thought）。スコアがベースライン平均プロンプトを下回るパターンを特定しフィルタリング。
    - **ルールベース:** 書き換えられたテキストから重要な単語を抽出し、ルールに基づいてテンプレートを変換（例: 会話形式の特定）。

