---
tags:
  - Kaggle
  - 物体検出
url: https://www.kaggle.com/competitions/czii-cryo-et-object-identification
startdate: 2024-11-07
enddate: 2025-02-06
---
**全体的な傾向:**

このコンペでは、3Dボリュームデータからの物体検出が課題であり、セグメンテーションベースの手法とヒートマップベースの手法が上位で採用されています。3D U-Netを基本としたアーキテクチャが多く見られ、データ拡張やアンサンブルも重要なテクニックとして活用されています。外部データ（シミュレーションデータ）の利用も一部で見られます。

**各解法の詳細:**

**1位**

- **アプローチ:** セグメンテーション（一部U-Net）と物体検出モデルのアンサンブル。外部データやシミュレーションデータは不使用。
- **アーキテクチャ:** MONAIのFlexibleUnet（エンコーダ: ResNet, EfficientNet-B3）、SegResNet、DynUnet。
- **アルゴリズム:** 3D U-Net、ResNet、EfficientNet、SegResNet、DynUnet。
- **テクニック:**
    - 7分割の実験IDに基づくクロスバリデーション。
    - 各エポック終了時に検証実験でクラス閾値をグリッドサーチで最適化。OOF予測で閾値を再調整。
    - 3D画像の標準化。
    - RandomCrop, Flip (各軸), Rotationによるデータ拡張。MixUpの独自実装。
    - 最終層の一つ前の特徴マップを使用する「一部U-Net」。
    - 背景クラスの重みを低く設定し、単一ピクセルをターゲットとする。
    - 重み付きCrossEntropy損失（beta-amylaseクラスも保持）。陽性ピクセルに高い重み。
    - コサイン学習率スケジューラ、混合精度学習。
    - 推論時のパッチ分割。
    - セグメンテーションモデルと物体検出モデルの予測を、ランクに基づいてスケーリングしてブレンド。
    - モデルのJITまたはTensorRTによるエクスポートによる推論高速化。

**2位**

- **アプローチ:** 軽量なセグメンテーションモデルのアンサンブル。セグメンテーション後、CC3Dで粒子中心を計算し、小さなクラスタをフィルタリング。
- **アーキテクチャ:** UNet3D, VoxResNet, VoxHRNet, SegResNet, DynUNet, DenseVNet, UNet2E3D。MONAI UNetをベースに正規化と活性化関数を調整。
- **アルゴリズム:** UNet3D、VoxResNet、VoxHRNet、SegResNet、DynUNet、DenseVNet。
- **テクニック:**
    - 公開LBスコアに基づいてモデルを選択。
    - 粒子タイプごとにカスタマイズされた半径のセグメンテーションマスク。
    - LionモデルとLuoziqianモデルで異なる学習設定（パッチサイズ、エポック数、オプティマイザ、損失関数、データ拡張）。
    - Lionモデル: AdamW, Tversky Loss, 重み付きCross-Entropy Loss, RandCropByLabelClassesdなど。
    - Luoziqianモデル: Early stopping, Dice Loss, Tversky Loss, スケールされたCross-Entropy Loss, RandCropByLabelClassesdなど。
    - 7種類のテスト時拡張 (TTA)。
    - 平均アンサンブル（重み付きも試行）。
    - 閾値ベースのクラスタリング（閾値0.15）。
    - クラスタサイズのフィルタリング。

**3位**

- **アプローチ:** 3D U-Netベースのセグメンテーションとcc3dによる後処理。Cross Entropy損失を使用。
- **アーキテクチャ:** Unet + ResNet101（segmentation_models_pytorch_3dを使用）。
- **アルゴリズム:** 3D U-Net、ResNet101。
- **テクニック:**
    - 4分割（7KF）の平均アンサンブル。
    - EMA（指数移動平均）。
    - 学習時の入力サイズ (64, 128, 128)、推論時の入力サイズ (64, 256, 256)。
    - 学習時のマスク半径を半分に。
    - フリップ (x, y, z軸)、軸の入れ替え (xとy)、異なるアルゴリズム（denoised, wbp, ctfdeconvolved, isonetcorrected）、simple copy past、mixupによるデータ拡張。
    - フリップ (x, y, z軸)、rot90 (x, y軸) による2種類のTTA。

**4位**

- **アプローチ:** ヒートマップベースの粒子点検出。2種類のUNetライクなモデル（2.5D-UNet）を使用。CVとLBの相関がない問題に対処するため、LBを重視。
- **アーキテクチャ:** yu4u's model (2.5D-UNet, ConvNeXt Nanoバックボーン), tattaka's model (軽量2.5D UNet, ResNetRS-50バックボーン)。
- **アルゴリズム:** UNet、ConvNeXt、ResNetRS。
- **テクニック:**
    - 粒子座標からガウス関数を用いてground truthヒートマップを作成（オフセット1.0を追加）。
    - yu4u's model: 2Dバックボーンの各ステージ出力を深度方向にプーリング、エンコーダとデコーダ間に3D畳み込み、ピクセルシャッフルによる最終ヒートマップ出力。
    - tattaka's model: 入力サイズ (32, 128, 128), Joint Pyramid Upsampling (JPU) をデコーダで使用。
    - MSEベースの損失関数（陽性・陰性サンプルをバランス）。
    - 4つのyu4u'sモデルと3つのtattaka'sモデルのアンサンブル。
    - TensorRT形式に変換して推論を高速化。
    - 非最大抑制 (NMS) によるローカル最大値検出。粒子タイプごとに異なる閾値でフィルタリング。
    - ピクセル座標から粒子座標への変換（オフセット補正、スケーリング）。

**5位**

- **アプローチ:** DeepFinderに触発されたネットワークアーキテクチャを用いたシンプルな粒子検出。
- **アーキテクチャ:** BatchNorm3dを入力層に追加、チャンネル数を削減した軽量なネットワーク（1.44MB）。最終アップサンプリングに転置畳み込みを使用。
- **アルゴリズム:** 3D CNN。
- **テクニック:**
    - 7つのボリュームデータセットの(5, 99)パーセンタイルを平均化してMin-Maxスケーリング。
    - ラベルを log2(radius) * 0.8 の半径の球として作成。
    - バッチサイズ4、パッチサイズ128x128x128で学習。
    - フリップ (全軸)、回転 (z軸)、平均と標準偏差のシフトによるデータ拡張。
    - Adamオプティマイザ、ラベルスムージングCross-Entropy損失。
    - float16精度での学習、勾配クリッピング。
    - 4つの異なるシードで学習したモデルのアンサンブル。
    - 推論時のパッチ分割（z軸方向は最小限のオーバーラップ、x/y軸方向はオーバーラップ+1）。
    - 3フリップと3回転によるTTA。
    - 接続成分分析によるバイナリマスクの後処理、面積の小さい成分を除去。

**6位**

- **アプローチ:** MONAIのsliding_window_inferenceを用いた推論と、複数のモデルの平均アンサンブル。
- **アーキテクチャ:** 2.5D UNet (エンコーダ: EfficientNet-B2, EfficientNetV2-B2, ConvNeXt-Nano, ResNet34d), MONAIの3D UNet, SegResNet。
- **アルゴリズム:** UNet、EfficientNet、ConvNeXt、ResNet、SegResNet。
- **テクニック:**
    - 10個の異なるモデルで推論を行い、予測マップを平均化。
    - 粒子タイプ固有の閾値で平均化されたマップを二値化。
    - 接続成分分析で粒子位置（重心）を計算。
    - 外れ値除去、Min-Max正規化。入力ボリュームを64x128x128にクロップ。
    - 粒子中心のバイナリマスクをラベルとして使用（半径*0.5以内を1）。
    - FocalTversky++損失を使用。
    - polnetで生成したシミュレーションデータで一部モデルを事前学習。
    - 推論時にsliding_window_inference（オーバーラップ0.25）、エッジ付近の予測を破棄。
    - TensorRTに変換して推論を高速化。
    - クロスバリデーションとLBに基づいて粒子固有の閾値を調整。

**7位**

- **アプローチ:** クラスごとのガウスヒートマップ予測を行う3Dセグメンテーションモデル。シミュレーションデータでの事前学習と実験データでのファインチューニング。
- **アーキテクチャ:** U-Net (バックボーン: ResNet50d, EfficientNetV2-M), DeepLab (バックボーン: ResNet50d)。
- **アルゴリズム:** U-Net、ResNet、EfficientNet、DeepLab。
- **テクニック:**
    - シミュレーションデータ全体で事前学習、実験データのwbpバージョンで検証。
    - パーセンタイルクリッピング、データセット固有のスケーリング。
    - スライディングウィンドウによるパッチ分割とランダムシフト。
    - シフト、CutMix、MixUp、RandomFlip、Affine（xy平面のみ）、Rot90（xy平面のみ）、ピクセル値拡張による強力なデータ拡張。
    - 重み付きBCE損失（陽性ピクセルに高い重み）。
    - コサイン学習率スケジューラ、AdamWオプティマイザ。
    - EMA（指数移動平均）。
    - 3つのモデルスープ（各4フォールド）のアンサンブル。
    - 4x TTA、4x スライディングウィンドウ推論。
    - ロジットを平均化してヒートマップを結合。
    - エッジアーティファクトを軽減するための傾斜付き重み関数。
    - ローカル最大値検出前にガウシアンブラー、検出後に重み付きボックス融合 (WBF)。
    - ロジット空間での閾値処理。
    - LBプロービングによるTP/FP/FNの推定。

**8位**

- **アプローチ:** 異なるモデルサイズ、パラメータ、学習データで学習された4つの3D U-Netモデルスープのアンサンブル。
- **アーキテクチャ:** MONAIの3D U-Net（異なるチャンネル数、ストライド、残差ユニット数）。
- **アルゴリズム:** 3D U-Net。
- **テクニック:**
    - パッチサイズ (128, 128, 128) で学習、(160, 384, 384) で25%オーバーラップのスライディングウィンドウ推論（ガウス再構成）。
    - フリップと転置による幾何学的TTA。
    - ガウシアンノイズでノイズ除去した合成データで事前学習。
    - MONAIのDiceCELoss、AdamWオプティマイザ、学習率低下。EMAも実験。
    - 7分割クロスバリデーション。
    - ロジットレベルでのモデル予測の結合。
    - 分水嶺セグメンテーションによる粒子の分離。
    - 粒子固有のブロブ閾値サイズ。

**9位**

- **アプローチ:** 3D ConvNeXtライクなモデルによるセグメンテーションと、可能な限り多くのモデルのアンサンブル。その後、cc3dで重心を計算し、DBSCANでクラスタリング。
- **アーキテクチャ:** カスタマイズされた3D ConvNeXtライクモデル（エンコーダ: 2D ConvNeXtを3D化、ステムと畳み込みブロックのカーネルサイズ変更、ブロック数削減、デコーダ: U-Netベース、基本的なUpsampleを使用）。
- **アルゴリズム:** ConvNeXt、U-Net、DBSCAN。
- **テクニック:**
    - 粒子タイプごとに調整された半径のground truthマスク。
    - エンコーダのカスタマイズ（2Dから3Dへの変換、ステムと畳み込みブロックの調整）。
    - デコーダに基本的なUpsampleを使用。
    - BCE損失。
    - 推論コードは Hengckのノートブックがベース、DBSCANのアイデアは linheshenのノートブックから。
    - 推論ウィンドウサイズ (32, 320, 320)、学習ウィンドウサイズ (32, 256, 256)。
    - TTAs are rot90, 180 and 270.
    - 正規化のみの前処理。
    - Rot90, 180, 270、XYZフリップによる学習時のデータ拡張。

**10位**

- **アプローチ:** 9つのヴィンテージ3D U-Netのアンサンブル。ほとんどがシミュレーションデータで事前学習後、コンペデータでファインチューニング。
- **アーキテクチャ:** MONAIのUNet (spatial_dims=3, channels=(48, 64, 80, 80, 128), stride_patterns=(2,2,2,1))。
- **アルゴリズム:** 3D U-Net。
- **テクニック:**
    - 実験IDに基づくtrain/validation分割。
    - MONAIのNormalizeIntensitydによる正規化。
    - MONAIのRandFlipd, RandRotated, RandRotate90dによるデータ拡張。MixUpも使用（alphaは小さい）。
    - Optunaによるハイパーパラメータ探索。PyTorch Lightningで学習。
    - AdamWオプティマイザ、コサイン学習率スケジューラ。
    - ファインチューニングの損失関数: Tversky損失とマルチクラスCrossEntropy損失の重み付き組み合わせ。
    - シミュレーションデータでの事前学習には、ファインチューニングと同じ損失、粒子方向ベクトルを目的とした損失、バグありの方向ベクトル損失の3種類を使用。
    - KLダイバージェンス最小化に基づく後処理による重複検出の分割。
    - 境界線と重心を用いた追加の後処理。