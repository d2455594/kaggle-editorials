---
tags:
  - Kaggle
url: https://www.kaggle.com/competitions/leap-atmospheric-physics-ai-climsim
startdate: 2024-04-19
enddate: 2024-06-16
---
**全体的な傾向:**

このコンペでは、気象シミュレーションの出力を予測することが課題であり、時系列データモデリングが中心となります。上位解法では、Transformer、LSTM、CNN、Squeezeformerなどの様々なニューラルネットワークアーキテクチャが用いられています。データの正規化、特徴量エンジニアリング（特に物理法則に基づいた特徴量）、損失関数の工夫（MAE、Smooth L1 Loss、補助損失）、アンサンブル学習などが重要なテクニックとして活用されています。大規模なデータセット（Hugging FaceのLEAPデータ）の利用も一般的です。

**各解法の詳細:**

**1位**

- **アプローチ:** Squeezeformerをベースとしたモデル。MAE損失、補助損失（時空間情報）、信頼性ヘッド、マスクされた損失を使用。複数のデータ表現、高解像度データ、ソフトクリッピングなどのデータ準備も重要。
- **アーキテクチャ:** Squeezeformer（修正版、ECAレイヤー追加）、GLUMlp予測ヘッド。
- **アルゴリズム:** AdamWオプティマイザ、ハーフコサイン減衰スケジューラ。
- **テクニック:**
    - **モデル:** 12ブロックのSqueezeformerモデル（次元数256/384/512）。
    - **損失関数:** MAE（平均絶対誤差）、補助損失（正規化された緯度/経度、年周期のsin/cos）、信頼性ヘッド（損失を予測）、マスクされた損失。
    - **データ準備:** 高解像度データを使用（低解像度とブレンド）、複数のデータ表現（特徴量ごとに異なる正規化）、風速特徴量、特徴量とターゲットのソフトクリッピング。
    - **後処理:** ダウンキャストとアップキャスト、不良ターゲットの平均値で置換、ptendトリック。
    - **検証:** ランダムに選択された低解像度および高解像度データの複数の検証セット。公開LBに対するアンサンブル検証。
    - **アンサンブル:** 13モデルのアンサンブル（それぞれわずかに異なる）。

**2位**

- **アプローチ:** 1D seq2seqマルチターゲット回帰タスクとして問題を捉え、様々なモデル構造を訓練し、検証セットのスコアに基づいてヒルクライミングアルゴリズムでアンサンブル。
- **アーキテクチャ:** ResLSTM、GF-ResLSTM、GF-CNN-LSTM、GF-LSTM-Mamba、GF-LstmMambaMixedなど、主にLSTMベースの様々なモデル。
- **アルゴリズム:** Smooth L1損失、補助Diff損失、コサインアニーリングスケジューラ、AdamWオプティマイザ。
- **テクニック:**
    - **データ:** Hugging Faceの低解像度データセット全体を使用。
    - **クロスバリデーション:** 最初の7年と8年目の前半（約7500万データポイント）で訓練。8年目の後半と9年目の1月をホールドアウト検証セット（約625000データポイント）として使用。
    - **モデル最適化:** Smooth L1損失、補助Diff損失（隣接レベルの差分）、コサインアニーリングスケジューラ。
    - **グループファインチューニング:** 368の特徴量を7つのグループに分け、フル出力で訓練後、各グループを再度ファインチューニング（1エポック）。
    - **後処理:** 標準偏差と平均で非正規化。ptend_q0002の特定変数を線形関係に基づいて調整。公式のサンプル提出ファイルの重み値を適用。
    - **アンサンブル:** ヒルクライミング法でブレンド重みを探索。

**3位**

- **アプローチ:** 各チームメンバーが個別のニューラルネットワークモデルを構築し、Camaroモデルの予測に対してGBDT回帰器で予測を洗練。最終予測はこれらの予測の重み付き平均。
- **アーキテクチャ:**
    - **Pao:** 1D CNN + Transformer + LSTM。
    - **Camaro:** CNNとTransformerの組み合わせ、またはTransformerのみ（CLIPエンコーダを使用）。
    - **Kmat:** FiLM 1D UNet。
- **アルゴリズム:** 1D CNN、Transformer、LSTM、FiLM、LightGBM（2ndステージ）。Huber損失、KLダイバージェンス損失、対照損失、BCE損失。AdamW、Adam。
- **テクニック:**
    - **Pao:** 元の特徴量と相対湿度、高さ方向の1次微分と2次微分。隣接する垂直レベル間の差を予測する補助損失。Row-lessフルトレーニング。
    - **Camaro:** フルデータセットと長時間のトレーニング。飽和水蒸気圧を特徴量として追加。隣接する垂直レベル間の差を予測する補助損失。
    - **Kmat:** 差分特徴量、相対湿度関連の特徴量。複数の正規化方法。温度、q000X、風ベクトル予測のための3つのヘッドブランチを持つFiLM 1D UNet。state_qドロップの分類ブランチ。
    - **2ndステージ:** LightGBMでptend_qを予測。
    - **アンサンブル:** 重み付き平均。Nelder-Meadを使用。1D-CNNスタッキング。

**4位**

- **アプローチ:** 複数のConvNeXtモデルとTransformerモデルのアンサンブル。特徴量エンジニアリングと前処理、2段階学習戦略。
- **アーキテクチャ:** ConvNeXt（1D入力向けに修正）、Transformer。
- **アルゴリズム:** AdamWオプティマイザ、Polynomial Decay Scheduler、WarmupDecayLR。SmoothL1Loss。
- **テクニック:**
    - **特徴量エンジニアリング:** 差分特徴量、類似特徴間の平均と差分平均。
    - **前処理:** 特徴量とラベルにStandardScalerを適用（train/test両データで計算）。極端な値をクリップ。スカラー値を時間シリーズデータに変換。
    - **学習:** 7エポック（ConvNeXt）、4エポック（Transformer）。投票数の少ないデータで初期学習、その後投票数の多いデータでファインチューニング。
    - **後処理:** 特定の値を `state * (1 / -1200)` に設定。
    - **アンサンブル:** 複数のConvNeXtモデルとTransformerモデルの重み付き平均。

**5位**

- **アプローチ:** 双方向LSTMベースのモデルのアンサンブル。各モデルは独自のバリエーションを持つ。
- **アーキテクチャ:** MLPエンコーダ・デコーダ、双方向LSTM（3-6層）、双方向GRU、FFNN。
- **アルゴリズム:** Huber損失。
- **テクニック:**
    - **データ前処理:** 低解像度とaqua-planetデータを混合、または低解像度と一部の高解像度データを混合。特徴量のエンジニアリング（liq_partition, imbalance, moisture, air_total, temp_humid, temp_diff, wind_diffなど）。入力と出力の標準化、一部入力の対数変換。
    - **モデル:** ワイド（隠れ層512）だが浅い（3層）双方向LSTM、単一の双方向GRU層、最終MLPエンコーダ。または、線形層で入力次元を拡張、深い（6層）双方向LSTM、1D平均プーリング層、平均層、連結、線形層のシーケンス。
    - **学習:** バッチサイズ4-5ファイルまたは4000-5000データポイント。Huber損失（delta=1）。単一モデルを混合データで最後まで訓練し、その後、わずかに異なる手順で同じモデルをファインチューニングして、効果的にアンサンブルできる個別のモデルを作成。低解像度と高解像度データを混合したモデルは、低解像度データと高解像度データのバッチをモデルで評価し、損失は低解像度データと高解像度データの損失の重み付き組み合わせ。
    - **アンサンブル:** 実験的に最適な重みを決定。

**7位**

- **アプローチ:** LSTM、Transformer、Conv1D、Squeezeformerを含む様々なモデルを使用。ドメイン知識に基づく追加特徴量。MAEまたはSmoothL1Lossで訓練後、MSEで追加訓練。Nelder-Mead法で最適化された重みによる重み付き平均アンサンブル。
- **アーキテクチャ:** Transformer + LSTM、LSTM、Conv1D、Squeezeformer。
- **アルゴリズム:** MAE、SmoothL1Loss、MSE、AdamW。コサインスケジューラ。
- **テクニック:**
    - **データ準備:** Hugging Faceの低解像度データセット全体を使用。差分特徴量、相対湿度比率、圧力差、水蒸気圧、氷率などの追加特徴量。
    - **モデル:** 畳み込み特徴抽出器、位置エンコーディング、Transformerエンコーダ、双方向LSTMブロック、ResNetブロック。
    - **損失:** MAEを使用し、重みが0のターゲット列とptend_q0002_[12, 26]のターゲット列をマスク。MSEによるファインチューニング。
    - **後処理:** ptend_q0002_[12, 26]に特定の後処理を適用。state_q0002/q0003が閾値以下の場合に追加の後処理。
    - **アンサンブル:** Nelder-Mead法で最適化された重みによる重み付き平均。

**8位**

- **アプローチ:** 主にBiLSTMから派生したseq2seqモデル。モデルのアンサンブルとターゲットのアンサンブル。
- **アーキテクチャ:** BiLSTM（6-8層）、BiGRU（8層）、BiLSTM+Transformer、BiLSTM+Attention、BiLSTM+TCN、BiLSTM+CNN。
- **アルゴリズム:** AdamWオプティマイザ、コサインアニーリングスケジューラ。SmoothL1Loss。
- **テクニック:**
    - **データ:** 最後の6ヶ月のサンプルデータで検証。
    - **モデル:** 基本的なBiLSTMモデルをベースに、Transformer、Attention、TCN、CNNなどを追加したバリエーション。
    - **アンサンブル:** モデルのアンサンブル（重み付き平均）とターゲットのアンサンブル。

**10位**

- **アプローチ:** 各メンバーの回帰モデルのアンサンブル。異なるアーキテクチャと学習条件を持つ23のモデル。
- **アーキテクチャ:** Conv + Transformer (+ LSTM)、CNN / U-Net、LSTM。
- **アルゴリズム:** 1-MSE損失（標準化されたターゲットの後）、AdamWオプティマイザ、コサインアニーリングスケジューラ。
- **テクニック:**
    - **データ:** 1-7年または1-8年の低解像度データを使用。一部モデルは高解像度データや疑似ラベルデータも使用。
    - **評価指標:** 1-MSEを使用（R2の代わりに）。
    - **モデル設計 (Bilzard):** Climate-invariant特徴量（相対湿度、プルーム浮力、正規化された熱フラックスなど）の抽出。信頼性認識MSE損失。ハードサンプルのドーピング。Conv-TransformerとPixel-ShuffleスタックUNet。Tanh正規化。ドロップアウトの削除。
    - **モデル設計 (Tereka):** Transformer + Convolution + LSTM。Learnable Positional Embedding。
    - **モデル設計 (Phalanx):** CNNとTransformer。
    - **モデル設計 (Ryches):** TBD。
    - **アンサンブル:** ツリー型のアンサンブル手法と、手動で調整された重みによる最終的な重み付きアンサンブル。ターゲットごとのアンサンブル重みを学習。